\documentclass[12pt]{report}

\usepackage[spanish]{babel}
\usepackage[margin=2.54cm]{geometry}
\usepackage[dvipsnames]{xcolor}
\usepackage{array, amssymb, amsthm, enumitem, fancyhdr, float, graphicx, hyperref, hologo, listings, mathtools, tikz, tikz-cd}
\usepackage[spanish, noabbrev]{cleveref}

\pagestyle{fancy}
\lhead{\footnotesize \leftmark}
\rhead{\footnotesize \rightmark}

\lstdefinestyle{estilo_pablo}{
	basicstyle = \ttfamily\footnotesize, 
	tabsize = 2, 
	commentstyle = \color{gray}, 
	keywordstyle = \color{cyan}, 
	stringstyle = \color{purple}, 
	tabsize = 1, 
	frame = tb, 
	breaklines = true, 
	showstringspaces = false, 
	numbers = left, 
	numberstyle = \footnotesize\color{gray}, 
	stepnumber = 1, 
	captionpos = b
}
\crefname{listing}{Código}{Códigos}
\crefname{section}{Sección}{Secciones}

\title{
	\huge
	\noindent\textbf{Fundamentos de la Ciencia de Datos}\\
	
	{\Large \textit{Práctica 1}}
	\vspace{1cm}
	
	\huge
	Grado en Ingeniería Informática\\
	Universidad de Alcalá\\
	
	\vspace{1cm}
	
	\includegraphics[scale=0.075]{img/logo}
}

\author{
	Pablo García García\\
	Abel López Martínez\\
	Álvaro Jesús Martínez Parra\\
	Raúl Moratilla Núñez
}

\date{
	\large{14 de noviembre de 2023}
}

\hypersetup{
	pdftitle = {Práctica 1}, 
	pdfauthor = {Pablo García García, Abel López Martínez, Álvaro Jesús Martínez Parra, Raúl Moratilla Núñez}, 
	pdfsubject = {Fundamentos de la Ciencia de Datos}, 
	pdfcenterwindow, 
	pdfnewwindow = true, 
	pdfkeywords = {Entrega de la PL1 de laboratorio correspondiente al Curso 2023-2024}, 
	bookmarksopen = true 
}

\newtheorem{exercise}{Ejercicio}[section]
\newcommand{\dt}{\text{dist}}
\newcommand{\ds}{\text{dens}}
\newcommand{\drm}{\text{drm}}

\begin{document}
	
	\renewcommand{\chaptername}{Parte}
	\renewcommand{\lstlistingname}{Código}
	\maketitle \thispagestyle{empty}
	
	\newpage
	
	\setcounter{tocdepth}{3}
	\tableofcontents
	\listoffigures
	
	\chapter*{Introducción}\addcontentsline{toc}{chapter}{Introducción}\pagestyle{plain}
	
		\section*{El lenguaje R}\addcontentsline{toc}{section}{El lenguaje R}
		
			El lenguaje R, es un software de uso gratuito comúnmente usado en tareas relacionadas con la estadística, como el análisis o visualización de datos; o en general la propia Ciencia de Datos. Para ello cuenta con una gran cantidad de paquetes y herramientas que facilitan el trabajo.  
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.15]{img/Rlogo}
				\caption{Logo del lenguaje R}
				\label{fig:logo_R}
			\end{figure}
		
			El CRAN (Comprehensive R Archive Network, \url{https://cran.r-project.org/}) es un repositorio de recursos en línea que se utiliza para facilitar la distribución, el intercambio y el acceso a una amplia gama de software y paquetes relacionados con el lenguaje de programación R. La página web de CRAN sirve como el portal central para acceder a estos recursos y ofrece una variedad de apartados y enlaces útiles para los usuarios de R. A continuación, proporcionamos una descripción de los distintos enlaces a los que se puede acceder desde la página principal del CRAN: 
			
			\begin{itemize}
				\item Mirrors: Esta sección permite a los usuarios seleccionar un espejo (mirror) cercano para descargar paquetes y recursos. Los espejos son servidores que almacenan copias de los paquetes y datos de CRAN, lo que ayuda a mejorar la velocidad de descarga y la disponibilidad de los recursos.
				
				\item What's new?: En esta sección, los usuarios pueden encontrar información sobre las últimas actualizaciones y novedades en el mundo de R y los paquetes disponibles en CRAN. Esto es útil para estar al tanto de las últimas características y mejoras.
				
				\item Search: El enlace ``Search'' permite a los usuarios buscar paquetes y recursos específicos en el repositorio de CRAN. Además, se puede utilizar la función de búsqueda avanzada del motor de búsqueda de Google.
				
				\item CRAN Team: Aquí se puede encontrar información sobre las personas y equipos que trabajan en el mantenimiento y desarrollo de CRAN. Es útil para conocer a las personas detrás de esta valiosa fuente de recursos.
				
				\item About R: Esta sección proporciona información sobre el lenguaje de programación R en general. Incluye enlaces a la página de inicio de R y a ``The R Journal'', una publicación académica relacionada con R.
				
				\item Software: Esta sección ofrece acceso a diversas fuentes y binarios relacionados con R, lo que permite a los usuarios descargar e instalar R en su sistema. También proporciona acceso a paquetes, Task Views y otros recursos.
				
				\item Documentation: Aquí los usuarios pueden encontrar documentación esencial relacionada con R. Esto incluye manuales, preguntas frecuentes (FAQs) y contribuciones de la comunidad para ayudar a los usuarios a comprender y utilizar R de manera efectiva.
			\end{itemize}
			
			En R, los paquetes son extensiones de software que contienen funciones, datos y documentación para realizar tareas específicas. Antes de utilizar un paquete, debes instalarlo y cargarlo en tu sesión de R. Algunas de las funciones más útiles para preparar los paquetes de un proyecto son:
			
			\begin{itemize}
				\item \textbf{Paquetes por defecto}: \\
				Mediante \texttt{getOption("defaultPackages")} se muestra una lista de los paquetes que se cargan automáticamente cuando inicias una sesión de R. Son los paquetes básicos que R carga por defecto. Para cambiar la lista de archivos que R carga por defecto podemos acceder a la siguiente ubicación (instalación de R por defecto):\\\texttt{C:/Program Files/R/R-4.3.1/library/base/R/RProfile}, y modificar el archivo como se observa en el \Cref{cod:rprofile}, añadiendo al vector \texttt{dp} los paquetes que deseemos. 
				
				\lstinputlisting[language = R, style = estilo_pablo, firstline = 46, lastline = 54, firstnumber = 46, caption = Modificación en fichero \texttt{Rprofile}, label = cod:rprofile]{C:/Program Files/R/R-4.3.1/library/base/R/Rprofile}
				
				\item \textbf{Instalación de paquetes}: \\
				La instalación de paquetes puede ser realizada de tres formas distintas:
				
				\begin{enumerate}[label = \textbf{\arabic*. }]
					\item \texttt{install.packages("nombre\_del\_paquete")}\\
					A esta función se le debe pasar por parámetro el nombre del paquete que se desea instalar.
					
					\item \texttt{install.packages("ubicacion\_del\_paquete", rep=NULL)}\\
					A la función también se le puede pasar por parámetros la ubicación del archivo, que recomendablemente debe estar en una carpeta temporal en ``c:/'', este archivo lo descargamos desde:\\ \url{https://cran.r-project.org/} $>$ \texttt{Packages} $>$ \texttt{Table of available packages, sorted by name} $>$ Elegimos el paquete y descargamos la versión \texttt{r-release} de la sección \texttt{Windows binaries}.
					
					\item \texttt{utils:::menuInstallPkgs()}\\
					Tras la ejecución de este comando aparecerá una ventana donde se podrá elegir el mirror desde el que se va a descargar el paquete, y tras elegir el mirror (Spain (Madrid) en nuestro caso), aparece otra ventana donde se puede elegir el paquete que se quiere instalar, tras hacer doble click, este se instalará automáticamente.
				\end{enumerate}
				
				\item \textbf{Información de un paquete}: \\
				Cuando ejecutas \texttt{library(help="nombre\_del\_paquete")}, R te mostrará información detallada sobre el paquete especificado. Esto incluye una descripción del paquete y una lista de las funciones que contiene, junto con sus descripciones.
				
				\item \textbf{Carga de paquetes}: \\
				Si ejecutas \texttt{library(nombre\_del\_paquete)} con el nombre de un paquete, R cargará el paquete en tu sesión para que puedas utilizar sus funciones y objetos.
				
				\item \textbf{Lista de paquetes instalados}: \\
				Al ejecutar \texttt{library()} sin argumentos, R te mostrará una lista de los paquetes que están actualmente cargados en tu sesión de R. Esto te permite verificar qué paquetes están disponibles para su uso.
				
				\item \textbf{Lista de paquetes cargados}: \\
				Mediante \texttt{search()} podemos ver un listado completo de los paquetes actualmente cargados en memoria.
				
			\end{itemize}
			
			A parte, es recomendable descargar y conocer a conciencia el manual y las viñetas de todos los paquetes que usemos en nuestros proyectos (disponible en la página web del CRAN).
		
		\section*{El lenguaje \LaTeX}\addcontentsline{toc}{section}{El lenguaje \LaTeX}

			Para la realización de esta práctica, se empleará el concepto de \textbf{programación literaria}, que consiste en crear un documento en el que se combine texto con código, de manera que este se pueda explicar y entender de una manera mucho más sencilla. Una forma de realizar esto con código R, es el uso del lenguaje \LaTeX{}, que es un sistema de composición de documentos enfocado al ámbito científico. Es algo similar a un lenguaje de marcas con el que poder definir la estructura de un documento, pero cuenta con la particularidad de que es un lenguaje Turing--completo, por lo que cualquier algoritmo puede ser implementado dando una mayor flexibilidad, aunque no sea su objetivo principal. Veremos ahora los pasos seguidos para su instalación. Para poder trabajar, lo mínimo que necesitaremos es un compilador de \LaTeX{}, en este caso se ha optado por la distribución \hologo{MiKTeX} que lo incluye, ya que estamos trabajando en Windows. Además, para una mayor comodidad trabajando con el código, se ha optado por el IDE \TeX{}studio, uno de los más conocidos en la comunidad. \\
			
			Una vez hemos tratado ambos lenguajes, necesitamos entender con qué tipos de extensiones se suelen trabajar para ver el proceso de integración con R (sin entrar en profundidad). Estas dependen de cómo queremos almacenar nuestro documento, o cómo están almacenadas dependencias de estos, como por ejemplo, imágenes. Esta tarea se realiza usando un compilador u otro. \\
			
			Para ello nos fijaremos en la \Cref{fig:extensiones}. Por ahora nos quedaremos con las extensiones que trabajaremos más a menudo, que serán \texttt{.Rnw}, \texttt{.tex}, y \texttt{.pdf}. La primera de ellas representan los archivos que tienen código \LaTeX{} y R ``mezclado'', la segunda aquellos que contienen código \LaTeX{} puro, y la última nuestro documento final. \\
			
			\begin{figure}[H]
				\centering
				\begin{tikzcd}
					& \texttt{.Rnw} \arrow[d] & \\
					& \texttt{.tex} \arrow[ld] \arrow[rd] \arrow[dd] & \\
					\texttt{.dvi} \arrow[rr] \arrow[rd] & & \texttt{.ps} \arrow[ld] \\
					& \texttt{.pdf} &               
				\end{tikzcd}
				\caption{Esquema de extensiones en \LaTeX}
				\label{fig:extensiones}
			\end{figure}
			
			Existen dos herramientas que nos permiten trabajar con archivos \texttt{.Rnw}, estas son Sweave y Knitr. A pesar de que en la asignatura ha sido propuesta la primera de ellas, optaremos por la segunda, pues existieron diversos errores al compilar archivos con esta, y al ser más antigua, los documentos finales tenían menos calidad. Knitr nos ofrece mayor calidad y un mejor formato en el código fuente R mostrado. Para instalarla basta con escribir \texttt{install.packages('knitr')} en una consola de R. Sweave viene ya por defecto con \texttt{utils}. \\
			
			Por último, se explicará cómo hemos agilizado el proceso de trabajo con Knitr y \TeX{}Studio. Lo primero será hacer que R cargue por defecto Knitr, para ello modificaremos el archivo \texttt{Rprofile} en \texttt{libray/base/R} dentro de la carpeta de instalación de R, añadiendo \texttt{knitr} al resto de paquetes que carga por defecto. Una vez hecho esto, iremos a la configuración de \TeX{}Studio, y aquí a \textit{Compilar}. En la zona \textit{Órdenes de usuario}, crearemos una nueva tal y como se ve en la \Cref{fig:orden}, de manera que le digamos dónde están los binarios de R, para que pueda crear un fichero \texttt{.tex}, y posteriormente invocar a nuestro compilador, para obtener nuestro documento en \texttt{.pdf}. \TeX{}Studio se encargará de reemplazar el símbolo \% por el nombre del archivo que le ordenamos compilar. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.7]{img/o_usuario}
				\caption{Creación de orden de usuario}
				\label{fig:orden}
			\end{figure}
			
			Ahora basta modificar el botón verde del IDE para que en vez de invocar al compilador \hologo{pdfLaTeX}, lleve a cabo la instrucción que le hemos dado. Para ello volveremos al menú de compilación en el que nos ubicábamos previamente, y observaremos la sección de \textit{Meta-Órdenes}. Modificaremos el valor del campo \textit{Compilador por defecto}, escribiendo \texttt{txs:///knitr} para que se ejecute la orden que previamente hemos creado, o podemos hacerlo de manera gráfica como se observa en la \Cref{fig:comp}. Ahora bastará pulsar el botón verde o F5 para ver a nuestra izquierda el código de nuestro documento, y a la derecha actualizado, el documento PDF final. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.7]{img/compilacion}
				\caption{Modificación de compilación}
				\label{fig:comp}
			\end{figure}
			
			Por último, para llevar un mejor control de versiones del proyecto, y de coordinación entre los miembros del grupo, se usará un repositorio de GitHub. Añadiremos un archivo \texttt{.gitignore} para no cargar en el repositorio los archivos temporales generados durante la compilación. Otra alternativa que se podría haber usado, es usar Overleaf (aquí usaríamos la extensión \texttt{.Rtex} en vez de \texttt{.Rnw}), ya que no sería necesaria la instalación de ningún software, y también trabaja con Knitr. Sin embargo, la integración de GitHub en Overleaf es de pago, por lo que optamos por usar la configuración explicada hasta el momento, para poder tener un mejor control de versiones sin coste alguno. \\
			
			Por último, mencionar que al igual que R posee su repositorio de paquetes (que ya hemos visto que incluye más cosas) llamado CRAN, \LaTeX{} que en realidad es ``un subconjunto'' del lenguaje \TeX{}, también tiene su propio portal llamado CTAN o Comprehensive \TeX{} Archive Network (\url{https://www.ctan.org/}) de donde se descargan los paquetes y otros materiales para el lenguaje. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.5]{img/ctan_lion}
				\caption{Mascota de \TeX{} y el CTAN}
				\label{fig:leon}
			\end{figure}
			
	\chapter{Ejercicios guiados}\pagestyle{fancy}
	
		En esta primera parte de esta práctica, repetirán los ejercicios explicados y realizados por el profesor en las clases de laboratorio, utilizando los mismos procedimientos vistos plasmándolos en este documento. 
	
		\section{Descripción de los datos}
		
			\begin{exercise}
				El primer conjunto de datos, que se empleará para realizar el análisis de descripción de datos, estará formado por datos de una característica cualitativa, nombre, y otra cuantitativa, radio, de los satélites menores de Urano, es decir, aquellos que tienen un radio menor de 50 Km, dichos datos, los primeros cualitativos nominales, y los segundos cuantitativos continuos, son: (Nombre, radio en Km): Cordelia, 13; Ofelia, 16; Bianca, 22; Crésida, 33; Desdémona, 29; Julieta, 42; Rosalinda, 27; Belinda, 34; Luna-1986U10, 20; Calíbano, 30; Luna-999U1, 20; Luna 1999U2, 15.
			\end{exercise}
			
			Para comenzar con la resolución de este ejercicio, deberemos escribir los datos en un fichero \texttt{.txt}, cumpliendo las siguientes normas: 
			
			\begin{itemize}
				\item Existirá una tabulación entre dato y dato. 
				\item La primera columna numera las filas, y en la primera fila se introduce un espacio y el nombre de las variables. 
				\item Se introducirá un salto de línea en la última fila
				\item Para los números decimales se utilizarán puntos. 
				\item Al escribir nombres, no se deberán introducir espacios. 
			\end{itemize}
			
			Obedeciendo a estas normas, copiamos los datos en un fichero llamado \texttt{satelites.txt}, y lo cargamos en R de la siguiente manera: 
			
			<<>>=
			s <- read.table("data/satelites.txt")
			print(s)
			@
			
			Ahora en la variable \texttt{s} tenemos un dataframe con los datos de nuestros satélites. En los dataframes se accede por \texttt{[fila, columna]}, y también podemos consultar las dimensiones con la función \texttt{dim}. Sería de esperar que nos dijera que tiene 12 filas (los 12 datos), y 2 columnas (\texttt{nombre} y \texttt{radio}). 
			
			<<>>=
			dim(s)
			@
			
			También podemos ordenar el dataframe, en función de una de las magnitudes (columnas), usando la función \texttt{order} aplicando recursivamente el concepto de acceder por filas y columnas. Veamos un ejemplo, si en \texttt{s} teníamos guardado nuestro dataframe, y queremos ordenar por \texttt{radio}, la manera de hacerlo sería la siguiente: 
			
			<<>>=
			s_ordered <- s[order(s$radio), ]
			print(s_ordered)
			@
			
			Podemos introducir nuevos criterios a la ordenación, como por ejemplo, hacerlo en orden descendente. Para esto usaremos la función \texttt{rev}. 
			
			<<>>=
			s_ordered_rev <- s[rev(order(s$radio)), ]
			print(s_ordered_rev)
			@
			
			También suele ser útil conocer cuántos elementos tiene una columna. Podemos averiguarlo con la función \texttt{length}, veamos un ejemplo. 
			
			<<>>=
			length(s$radio)
			@
			
			Otro valor que nos podemos plantear calcular es el rango. Para ello podemos usar las funciones \texttt{max} y \texttt{min}. Debemos tener cuidado con la función \texttt{range} y no confundirnos, pues nos dará los valores máximo y mínimo. 
			
			<<>>=
			r <- max(s$radio) - min(s$radio)
			print(r)
			range(s$radio)
			@
			
			Para una mejor lectura, podemos cambiar la forma de obtener la columna de los radios: 
			
			<<>>=
			radio <- s$radio
			@
			
			La idea de calcular la diferencia de el máximo y el mínimo a mano parece funcionar, sin embargo, para futuros casos sería más ágil tener codificada una función como la siguiente. 
			
			<<>>=
			rango <- function(radio){max(radio) - min(radio)}
			rango(radio)
			@
			
			Sin embargo, al salir de R, la definición de la función se pierde, por lo que deberemos guardarla en un fichero, y posteriormente cargarlo en futuras ejecuciones. Lo haremos de la siguiente manera: 
			
			<<>>=
			dump("rango", file = "fn/rango.R")
			source("fn/rango.R")
			@
			
			Volviendo al estudio de nuestros datos, veamos cómo calcular las diferentes frecuencias. Como en R no existe una función para las frecuencias relativas, se definirá y guardará una propia. 
			
			{\small
			<<>>=
			fabs_radio <- table(radio)
			fabsacum_radio <- cumsum(fabs_radio)
			frecrel <- function(r){table(r)/length(r)}
			dump("frecrel", file = "fn/frecrel.R")
			
			print(fabs_radio)
			print(fabsacum_radio)
			print(frecrel(radio))
			@
			}
			
			Otro valor que podemos calcular es la media aritmética de los datos, para ello se cuenta con la función \texttt{mean}. 
			
			<<>>=
			mr <- mean(radio)
			print(mr)
			@
			
			Ahora calcularemos la desviación típica, para ello se cuenta con la función \texttt{sd}. 
			
			<<>>=
			sdr <- sd(radio)
			print(sdr)
			@
			
			Sin embargo, el resultado obtenido no es el esperado. Esto se debe a que esta función realiza el siguiente cálculo
			$$
			s = \sqrt{\frac{\displaystyle\sum_{i=0}^n (x_i-\bar{x})^2}{n-1}}
			$$
			que es más utilizado en inferencia estadística, porque hace que se parezca más a una campana de Gauss (menos sesgo), mientras que la fórmula vista en clase utiliza un factor de $n$ en vez de $n-1$ en el denominador (dentro de la raíz). Para ello, el profesor lo corrigió de la siguiente manera: 
			
			<<>>=
			sdr2 <- sqrt((sdr^2)*(length(radio)-1)/length(radio))
			print(sdr2)
			@
			
			En realidad lo que se está realizando es el siguiente ``ajuste'': 
			$$
			s' = \sqrt{s^2\cdot\frac{n-1}{n}}
			$$
			
			Una vez hemos visto cómo se calcula la desviación típica, podremos ver cómo calcular la varianza. Como sabemos que es el cuadrado de la desviación típica, bastaría con elevar al cuadrado si no fuera por el ``fallo'' de $n-1$ visto previamente. En este caso, el profesor lo arregló para el caso particular de la siguiente manera: 
			
			<<>>=
			varr <- var(radio)
			varr <- 11/12 * varr
			print(varr)
			@
			
			Otro de los valores que se ha enseñado cómo calcular, es la mediana. Para este caso existe la función \texttt{median}. 
			
			<<>>=
			medianr <- median(radio)
			print(medianr)
			@
			
			En último lugar, el profesor enseñó cómo calcular cuantiles, y para ello mostró la función \texttt{quantile}, pero se mencionó que se obtienen resultados diferentes a los esperados debido a la forma que tiene de calcularlos, y se deberá programar. Aquí se muestra un ejemplo de cómo se calcularía el primer cuartil. 
			
			<<>>=
			cuar1 <- quantile(radio, 0.25)
			print(cuar1)
			@
			
			Como añadido, el profesor explicó cómo abrir un ejemplo de Sweave, cómo pasarlo a un fichero que \LaTeX{} pudiese leer, y cómo compilarlo a PDF. Las instrucciones son las que se verán a continuación, aunque como ya se explicó en la introducción, usaremos otra forma de trabajar con estos archivos a lo largo de la práctica. 
			
			\begin{verbatim}
				rnwfile<-system.file("Sweave", "example-1.Rnw", package="utils")
				Sweave(rnwfile)
				tools::texi2pdf("example-1.tex")
			\end{verbatim}
		
		\section{Asociación}
		
			\begin{exercise}
				El segundo conjunto de datos, que se empleará para realizar el análisis de asociación, estará formado por las siguientes 6 cestas de la compra: \{Pan, Agua, Leche, Naranjas\}, \{Pan, Agua, Café, Leche\}, \{Pan, Agua, Leche\}, \{Pan, Café, Leche\}, \{Pan, Agua\}, \{Leche\}.
			\end{exercise}
				
			Lo primero explicado por el profesor fue la preparación de los datos proporcionados para que \texttt{arules} fuese capaz de tratar con ellos. Para ello se introduce una matriz de ceros y unos mediante el paquete \texttt{Matrix}, que indique en cada suceso, qué elementos contiene. La matriz es la siguiente:
			$$
			\begin{pmatrix}
				1 & 1 & 0 & 1 & 1\\
				1 & 1 & 1 & 1 & 0\\
				1 & 1 & 0 & 1 & 0\\
				1 & 0 & 1 & 1 & 0\\
				1 & 1 & 0 & 0 & 0\\
				0 & 0 & 0 & 1 & 0
			\end{pmatrix}
			$$
			
			Además, deberemos indicar las dimensiones de esta matriz $(6\times5)$, que estamos introduciendo los datos por filas (\texttt{byrow=TRUE}), y con \texttt{dimnames} ponemos los nombres a las filas y las columnas. El código es el siguiente. 
			
			<<>>=
			muestra <- Matrix(c(1, 1, 0, 1, 1,  
			1, 1, 1, 1, 0,  
			1, 1, 0, 1, 0,  
			1, 0, 1, 1, 0,  
			1, 1, 0, 0, 0,  
			0, 0, 0, 1, 0), 6, 5, byrow = TRUE, dimnames = list(
			c("suceso1", "suceso2", "suceso3", "suceso4", "suceso5", "suceso6"), 
			c("Pan", "Agua", "Café", "Leche", "Naranjas")), sparse=TRUE)
			muestra
			@
			
			A continuación, se ha enseñado cómo mostrar la matriz con puntos y barras, en vez de con unos y ceros. Se consigue con la función \texttt{as} y el parámetro \texttt{nsparseMatrix}. 
			
			<<>>=
			muestrangCMatrix <- as(muestra, "nsparseMatrix")
			muestrangCMatrix
			@
			
			Sin embargo, para el algoritmo debemos pasarle justo la transpuesta de la matriz con la que trabajamos, por ello se utiliza la función \texttt{t}. 
			
			<<>>=
			transpmuestrangCMatrix <- t(muestrangCMatrix)
			transpmuestrangCMatrix
			@
			
			Podemos consultar algunos datos acerca de los datos de nuestra matriz podemos usar la función \texttt{as} con el parámetro \texttt{transactions}. Además, con \texttt{summary} podemos ver un resumen de algunos parámetros básicos de los datos que contiene la matriz. 
			
			<<>>=
			transacciones = as(transpmuestrangCMatrix, "transactions")
			transacciones
			summary(transacciones)
			@
			
			Finalmente, podemos ejecutar el algoritmo apriori llamando a la función \texttt{apriori} del paquete \texttt{arules}. Definimos el soporte con un valor del 50\%, y la confianza con 80\%. 
			
			<<>>=
			asociaciones = apriori(transacciones, parameter = 
			list(support = 0.5, confidence = 0.8))
			@
			
			Podemos ver el resultado del algoritmo con la función \texttt{inspect}. 
			
			<<>>=
			inspect(asociaciones)
			@
			
			Aquí observamos el resultado del algoritmo. Debemos ignorar las dos primeras filas, pues no tiene sentido alguno que $\varnothing \rightarrow$ \{Leche\}, o que $\varnothing \rightarrow$ \{Pan\}, aparecen por cómo el autor del paquete codificó el algoritmo. En el resto de casos $A \rightarrow B$, nos indica cómo de probable es comprar $B$ cuando se compra $A$ (en función del soporte y la confianza provistas). 
			
			
		\section{Detección de datos anómalos}
			
			\subsection{Técnicas estadísticas}
			
				\begin{exercise}
					El tercer conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas con base estadística, estará formado por los siguientes 7 valores de resistencia y densidad para diferentes tipos de hormigón \{Resistencia, Densidad\}: \{3, 2; 3.5, 12; 4.7, 4.1; 5.2, 4.9; 7.1, 6.1; 6.2, 5.2; 14, 5.3\}. Aplicar las medidas de ordenación a la resistencia y las de dispersión a la densidad.
				\end{exercise}
				
				\subsubsection{Caja y Bigotes}\label{subsub:caja_bigotes}
				
					Es una herramienta gráfica utilizada en estadística para representar la distribución de un conjunto de datos y detectar sucesos anómalos o outliers. Para realizar el cálculo de los outliers en clase, se introdujeron los datos en una matriz mediante \texttt{matrix}, luego se transpuso y se pasó a un \texttt{dataframe}. Para esta primera técnica vamos a usar la primera columna (\texttt{resistencia}).
					
					<<>>=
					muestra=t(matrix(c(3,2,3.5,12,4.7,4.1,5.2,4.9,7.1,6.1,6.2,5.2,14,5.3),
					2,7,dimnames=list(c("resistencia","densidad"))))
					
					(muestra=data.frame(muestra))
					@
					
					Una forma de obtener los outliers es mediante la función \texttt{boxplot}, pasándole la columna de los datos, el grado de outlier (\texttt{range}) o distancia a la que el suceso se considera outlier, y por último \texttt{plot=FALSE}, que se usa para no mostrar el gráfico como tal y solo sacar la información por el terminal.
					
					<<>>=
					(boxplot(muestra$r, range=1.5, plot=FALSE))
					@
					
					Como podemos ver en \texttt{\$out}, se obtiene que el suceso outlier es el 14, que como se vio en el ejercicio de la clase de teoría es correcto, pero, si nos fijamos en \texttt{\$conf}, se pueden ver los límites del intervalo, pero estos no coinciden con los vistos en clase. Esto se debe a que al igual que ocurría al usar la función \texttt{sd} para el cálculo de la desviación, R utiliza un factor de $n-1$ en vez de $n$, por lo que no son los valores exactos. \\
					
					Ahora vamos a hacerlo mediante el cálculo de los cuartiles como se vio en ejercicios anteriores. Además, se han calculado los límites del intervalo mediante la siguiente ecuación.
					
					$$
					(Q_1 - d(Q_3 - Q_1), Q_3 + d(Q_3 - Q_1))
					$$
					
					<<>>=
					(cuar1r=quantile(muestra$r, 0.25))
					
					(cuar3r=quantile(muestra$r, 0.75))
					
					(int=c(cuar1r-1.5*(cuar3r-cuar1r), cuar3r+1.5*(cuar3r-cuar1r)))
					@
					
					Por último, se iteran los elementos de la muestra y se comprueba para cada uno si es menor que el límite inferior del intervalo o si es mayor que el límite superior.
					
					<<>>=
					for (i in 1:length(muestra$r)) {
						if (muestra$r[i] < int[1] || muestra$r[i] > int[2]) {
							print("el suceso")
							print(i)
							print("es un suceso anómalo o outlier")
						}
					}
					@
					
					En este ejercicio, al igual que se vio en clase, el suceso outlier es el que está en la posición número 7, es decir el elemento 14.
				
				\subsubsection{Media y Desviación}
				
					Otra manera de buscar sucesos outliers usando técnicas con base estadística es mediante el uso de la media y la desviación típica. Aquí vamos a usar la otra columna del dataframe (\texttt{densidad}), mediante el uso de las funciones \texttt{mean} y \texttt{sd} sacamos ambos valores, que unimos en los límites del intervalo mediante la siguiente ecuación.
					
					$$
					(\bar{x}_a - d\cdot s_a, \bar{x}_a + d\cdot s_a)
					$$
					
					<<>>=
					(media = mean(muestra$d))
					
					(desv = sd(muestra$d))
					
					(int=c(media-2*desv, media+2*desv))
					@
					
					Se puede ver que los valores inferior y superior del intervalo no son iguales que en el ejercicio que realizado en clase, esto se debe a que, como ya se vio, la desviación típica se calcula con un factor de $n-1$ en vez de $n$, por lo que arreglando el cálculo de la desviación quedaría así.
					
					<<>>=
					(desv = sqrt(sd(muestra$d)^2 *
					(length(muestra$d)-1) / length(muestra$d)))
					
					(int=c(media-2*desv, media+2*desv))
					
					for (i in 1:length(muestra$d)) {
						if (muestra$d[i] < int[1] || muestra$d[i] > int[2]) {
							print("el suceso")
							print(i)
							print("es un suceso anómalo o outlier")
						}
					}
					@
					
					Como resultado, se obtienen los valores del intervalo correctos y se puede ver que el suceso anómalo es el que se encuentra en la posición 2, es decir el elemento 12.
				
			\subsection{Proximidad y densidad}
			
				\begin{exercise}
					El cuarto conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas basadas en la proximidad y en la densidad, estará formado por las siguientes 5 calificaciones de estudiantes: 1. \{4, 4\}; 2. \{4, 3\}; 3. \{5, 5\}; 4. \{1, 1\}; 5. \{5, 4\} donde las características de las calificaciones son: (Teoría, Laboratorio).
				\end{exercise}
				
				\subsubsection{Algoritmo $k-$vecinos}
				
					El algoritmo $k-$vecinos utilizado para identificar outliers basado en distancias, consiste en calcular la distancia de un punto a sus $k$ vecinos más cercanos y considerar los puntos con distancias mayores a un cierto valor (grado de outlier) como anómalos.\\
					
					En clase se añadieron todos los datos de la nueva muestra a una matriz, que luego fue transpuesta para tener los datos dispuestos como requería el cálculo de distancias. Se calcularon las distancias euclídeas mediante la función \texttt{dist} y se guardó en una matriz de $5 \times 5$, para poder visualizar la distancia de cada punto hacia el resto. El cálculo de esta distancia se realiza de la siguiente manera.
					
					$$
					\dt(p, q) = \sqrt{\sum_{i=1}^n(p_i-q_i)^2}
					$$
					
					<<>>=
					muestra=matrix(c(4,4,4,3,5,5,1,1,5,4),2,5)
					muestra=t(muestra)
					distancias=as.matrix(dist(muestra))
					(distancias=matrix(distancias,5,5))
					@
					
					Mediante el siguiente bucle, se itera cada punto y ordena de menor a mayor las distancias hacia los demás puntos.
					
					<<>>=
					for (i in 1:5) {
						distancias[,i] = sort(distancias[,i])
					}
					
					(distanciasordenadas=distancias)
					@
					
					Por último, se itera cada punto de la matriz de distancias ordenadas y comprobamos si el elemento $k-$éismo está a una distancia mayor de $2.5$ (elegido arbitrariamente), donde el punto se consideraría outlier.
					
					En el código se puede ver que se elige el elemento 4 en vez del 3 que era la \texttt{k} elegida para resolverlo, esto se debe a que la primera fila de valores, son las distancias desde cada punto hacia sí mismo, es decir, siempre 0, por lo que los descartamos en el conteo de los \texttt{k} elementos.
					
					<<>>=
					for (i in 1:5) {
						if (distanciasordenadas[4,i] > 2.5) {
							print(i)
							print("es un suceso anómalo o outlier")
						}
					}
					@
					
					Podemos ver que como salida se obtiene que el punto 4 es un suceso anómalo o outlier, al igual que ocurría en el ejercicio resuelto en teoría.
				
				\subsubsection{Algoritmo LOF}
				
					Como último ejercicio realizado en clase, se ha empleado el algoritmo LOF (Local Outlier Factor) para identificar outliers basado en distancias, que evalúa la densidad local de puntos en relación con sus vecinos, identificando valores anómalos en regiones menos densas que el entorno circundante.\\
					
					Se obtiene una matriz de distancias haciendo uso de la función \texttt{dist}, pero en este caso se pasa como parámetro el método que queremos que sea usado para calcular la distancia (\texttt{method="manhattan"}), en este caso el método \textit{Manhattan}, que se calcula de la siguiente manera.
					
					$$
					\dt(x_i, x_j) = |x_{i_1} - x_{j_1}| + |x_{i_2} - x_{j_2}|
					$$
					
					<<>>=
					(distanciasM=as.matrix(dist(muestra, method="manhattan")))
					@
					
					Para finalizar, el profesor nombró algunos paquetes que realizaban una implementación no simplificada del algoritmo, estos son \texttt{RLof}, \texttt{DDoutlier} y \texttt{DMwR}, pero en el segundo ejercicio autónomo de detección de datos anómalos, se implementará un código propio, que realice las simplificaciones oportunas.
	
	\chapter{Ejercicios autónomos}
	
		\section{Descripción de los datos}\label{sec:descrip_auto}
		
			\begin{exercise}
				El primer conjunto de datos, que se empleará para realizar el análisis de descripción de datos, estará formado por datos de una característica cuantitativa, distancia, desde el domicilio de cada estudiantes hasta la Universidad, dichos datos, cuantitativos continuos, son: 16.5, 34.8, 20.7, 6.2, 4.4, 3.4, 24, 24, 32, 30, 33, 27, 15, 9.4, 2.1, 34, 24, 12, 4.4, 28, 31.4, 21.6, 3.1, 4.5, 5.1, 4, 3.2, 25, 4.5, 20, 34, 12, 12, 12, 12, 5, 19, 30, 5.5, 38, 25, 3.7, 9, 30, 13, 30, 30, 26, 30, 30, 1, 26, 22, 10, 9.7, 11, 24.1, 33, 17.2, 27, 24, 27, 21, 28, 30, 4, 46, 29, 3.7, 2.7, 8.1, 19, 16.
			\end{exercise}
			
			Para comenzar, se han introducido todos los datos en un fichero CSV. Para realizar este fichero se ha abierto un fichero Excel y se han ido introduciendo los datos en la primera columna. Cabe destacar que la primera fila no corresponde a ningún valor ya que se ha puesto \texttt{Distancia(km)} para mantener la estructura con respecto al ejercicio guiado. Una vez han sido introducidos todos los datos, guardamos el fichero con extensión \texttt{.csv}. Para leer este fichero dentro de R se hace uso de la función \texttt{read.csv}, perteneciente al paquete por defecto \texttt{utils}. Esta función en realidad es un uso diferente de la función \texttt{read.table} orientado a la lectura de ficheros CSV. Esta función lee el archivo en formato tabla y a partir de él crea un dataframe haciendo corresponder las filas y las columnas de la tabla. La función empleada ha sido \texttt{read.csv} primeramente porque es un fichero CSV y además porque está delimitado por comas (en caso de haber estado delimitado por punto y coma se debería haber usado \texttt{read.csv2}. Se observa en la siguiente línea de código cómo se ha creado un archivo \texttt{distancia\_universitarios.csv} siguiendo la estructura mencionada previamente. Con este fichero creado basta con llamar a la función \texttt{read.csv} pasando como parámetro el fichero. Si el archivo estuviera en otro directorio, habría que pasar por parámetro la ruta donde se encuentra dicho archivo.
			
			<<>>=
			fichero = read.csv("data/distancia_universitarios.csv")
			fichero
			@
			
			Como se puede observar, se ha leído correctamente el fichero, creando el dataframe con los datos leídos. Al ser un CSV delimitado por comas, hay que tener cuidado con los números decimales y separar estos por un punto, ya que si se separa por comas, se leerán dos datos en vez de uno.\\ 
			
			Como se v a trabajar todo el rato con la columna \texttt{Distancia} del dataframe, para no tener que acceder repetidamente a esta, podemos definirla en una variable nueva a la que llamaremos \texttt{distancias}, de tal forma que no se tenga que estar haciendo \texttt{fichero\$Distancia} repetidamente.
			
			<<>>=
			distancias = fichero$Distancia
			@
			
			Para conocer la longitud de \texttt{distancias}, se ha decidido elaborar una función propia, la cual nos devolverá un escalar con el número de elementos que contenga nuestra lista (distancias en este caso). 
			
			<<>>=
			len = function(list){
				count = 0
				for (element in list){
					count = count + 1
				}
				count
			}
			@
			
			La función \texttt{len} se basa en un contador el cual se inicializa a 0 y, por medio de un bucle, iterar todos los elementos de la lista y aumentar en 1 cada vez que haya un nuevo elemento. Por último, se devolverá el contador. Esta función será fundamental en otras funciones tal y como veremos más adelante. Veamos cuántas distancias se tienen:
			
			<<>>=
			(longitud = len(distancias))
			@
			
			Observamos se tienen 73 elementos, es decir, 73 distancias. La próxima utilidad que se necesita es la ordenación de la lista de distancias. Para ello se ha elaborado una función que ordenará la lista en sentido ascendente o descendente utilizando el método de la burbuja. \\
			
			El método de la burbuja consiste en ir evaluando por pares todos los elementos de una lista, de tal forma que se vayan reposicionando según el sentido en el que se esté ordenando. En caso de ir ordenando en sentido ascendente, el mayor elemento de la lista se irá reposicionando hasta llegar a la derecha del todo. En caso de hacerlo en sentido descendente, el elemento que quedará a la derecha del todo será el menor. Conforme se vaya avanzando, tendremos por cada iteración un elemento más colocado a la derecha del todo, y así sucesivamente hasta que todos los elementos queden ordenados. Esto se consigue en un tiempo $\mathcal{O}(n^2)$. La función que realiza este método de ordenación es la siguiente:
			
			<<>>=
			bubble = function(list, asc = TRUE){
				n = len(list)
				direccion = ifelse(asc, 1, -1)
				for (i in 2:n){
					for (j in 1:(n-1)){
						if (list[j] * direccion > list[j+1] * direccion){
							temp = list[j]
							list[j] = list[j+1]
							list[j+1] = temp
						}
					}
				}
				list
			}
			@
			
			A esta función se le deberá pasar la lista que se quiere ordenar y \texttt{TRUE} o \texttt{FALSE} para indicar en el sentido que se quiere ordenar. En caso de ser \texttt{TRUE} se ordenará de manera ascendente, y en caso de \texttt{FALSE} se ordenará de forma descendente. Por defecto, si solo se pasa como parámetro la lista, se ordenará de forma ascendente.\\
			
			Además, el algoritmo de ordenación de la burbuja hace uso de la variable \texttt{direccion}, la cual adquiere los valores de 1 (en sentido ascendente) y -1 (en sentido descendente). Esto se consigue con la función \texttt{ifelse} del paquete \texttt{base}, a la cual se le pasa un valor booleano y dos valores. En función del valor booleano, si este es \texttt{TRUE} se coge el primer valor y si es \texttt{FALSE} el segundo. El valor escogido es asignado a la variable\texttt{direccion}. Esta cambiará o no el signo de los elementos de la lista que se está ordenando. En los números positivos, cuanto mayor sea el valor mayor será este, y en los negativos al revés. Si se ordena una lista de números negativos quedará a la derecha del todo el menor valor al ser este el número mayor. Esto se puede generalizar al sentido de ordenación de la lista.\\
			
			Hagamos la prueba con la lista de distancias:
			
			{\small 
			<<>>=
			distancias_asc = bubble(distancias)
			distancias_asc
			
			distancias_desc = bubble(distancias, FALSE)
			distancias_desc
			@
			}
			
			Con la lista ordenada, se puede saber de forma muy sencilla el rango. Previamente, en los ejercicios guiados, se tenía que llamar a las funciones \texttt{max} y \texttt{min}. Con la lista ordenada, se pueden acceder a estos valores, ya que estarán en el primer y último índice en función del sentido en el que hayamos ordenado la lista. Es por ello que resulta muy fácil crear una función rango.
			
			<<>>=
			rank = function(list){
				ordered_list = bubble(list)
				ordered_list[len(ordered_list)] - ordered_list[1]
			}
			@
			
			Primeramente, se ha ordenado la lista en orden ascendente, de tal forma que el valor máximo se encontrará en el último índice y el valor mínimo en el primero. Para calcular el rango se resta al elemento del último índice, el del primero. Se comprueba la función y se observa que se obtiene un rango de 45.
			
			<<>>=
			rango_dist = rank(distancias)
			rango_dist
			@
			
			Ahora se realizará el cálculo de las frecuencias absoluta y relativa y sus respectivas acumuladas. Para ello, nuevamente se crea una función para cada una. La primera que realizaremos y en la que se basará el resto, será la frecuencia absoluta. El código de la función es el siguiente:
			
			<<>>=
			absolute_freq = function(list){
				ordered_list = bubble(list)
				n = len(ordered_list)
				elements = vector()
				frequencies = vector()
				i = 1
				while (i <= n){
					actual_element = ordered_list[i]
					elements = append(elements, actual_element)
					actual_freq = 0
					j = i
					while(j <= n & actual_element == ordered_list[j]){
						actual_freq = actual_freq + 1
						j = j+1
					}
					frequencies = append(frequencies, actual_freq)
					i = j
				}
				rbind(elements, frequencies)
			}
			@
			
			El algoritmo consiste en iterar toda la lista. Se tienen dos listas auxiliares, una de elementos y otra de las frecuencias de esos elementos. Con la lista ordenada, cada vez que se encuentra un elemento distinto del anterior, lo se apunta en la lista de elementos, y mientras se continua iterando la lista, se van apuntando en un contador auxiliar las veces que va apareciendo ese elemento. Nótese que el elemento va a aparecer contiguo y no va a volver a aparecer en el resto de la lista, ya que previamente ha sido ordenada. De esta forma, se encuentra un elemento, se cuentan las veces contiguas que aparece y cuando aparece otro elemento, se apuntan las frecuencias del anterior y se inicia el mismo procedimiento con el siguiente elemento. Una vez se completa la iteración de la lista,  se devuelve con \texttt{rbind} una matriz que contiene ambas listas de elementos y sus correspondientes frecuencias.\\
			
			Para esta función se han utilizado las funciones de \texttt{append} (paquete base) que devuelve un vector con la lista que se pasa como parámetro y el elemento que se introduce como parámetro concatenado a la derecha del mismo, y la función \texttt{rbind} (paquete base), que devuelva una matriz con los vectores que se pasan como parámetros a modo de fila. Comprobamos las frecuencias absolutas:
			
			{\small
			<<>>=
			frecuencia_abs = absolute_freq(distancias)
			frecuencia_abs
			@
			}
		
			Una vez realizadas las frecuencias absolutas pasaremos a realizar las frecuencias relativas. La frecuencia relativa no es más que la frecuencia absoluta de un elemento dividido entre el total de elementos. Para realizar este cálculo se disponen de todas las herramientas, ya que se tiene la función \texttt{len}, que dice cuántos elementos hay, y la función de frecuencias absolutas que acabamos de realizar. Se puede codificar otra función que devuelva una matriz (con \texttt{rbind} al igual que se ha visto en el ejercicio anterior) con los elementos distintos de la lista y su frecuencia absoluta dividida entre la longitud de la misma. Siguiendo esta idea, el código de la función es el siguiente.
			
			<<>>=
			relative_freq = function(list){
				f_abs = absolute_freq(list)
				elements = f_abs[1,]
				abs_fvalues = f_abs[2,]
				rbind(elements,abs_fvalues/len(list))
			}
			@
			
			Se comprueban las frecuencias relativas de la lista.
			
			{\small
			<<>>=
			frecuencia_rel = relative_freq(distancias)
			frecuencia_rel
			@
			}
			
			Por último, elaboraremos dos funciones para las frecuencias acumuladas absoluta y relativa. Con todas las frecuencias de cada elemento y la lista ordenada se puede iterar la lista de frecuencias e ir sumando para cada elemento la suma de las frecuencias de los elementos menores o iguales al elemento del que se está calculando. Dependiendo de qué frecuencia acumulada se esté calculando se tendrá que trabajar con la función de frecuencias absolutas (\texttt{absolute\_freq}) o con la de frecuencias relativas (\texttt{relative\_freq}). Se irá iterando cada elemento y se irá creando un nuevo vector con la frecuencia acumulada. Los códigos de las funciones que realizan la frecuencia absoluta acuulada y la frecuencia relativa acumulada son respectivamente los siguientes:
			
			<<>>=
			acum_absolute_freq = function(list){
				f_abs = absolute_freq(list)
				elements = f_abs[1,]
				abs_fvalues = f_abs[2,]
				acum_abs_fvalues = vector()
				acum = 0
				for (i in 1:len(elements)){
					acum = acum + abs_fvalues[i]
					acum_abs_fvalues = append(acum_abs_fvalues, acum)
				}
				rbind(elements, acum_abs_fvalues)
			}
			@
			
			<<>>=
			acum_relative_freq = function(list){
				f_rel = relative_freq(list)
				elements = f_rel[1,]
				rel_fvalues = f_rel[2,]
				acum_rel_fvalues = vector()
				acum = 0
				for (i in 1:len(elements)){
					acum = acum + rel_fvalues[i]
					acum_rel_fvalues = append(acum_rel_fvalues, acum)
				}
				rbind(elements, acum_rel_fvalues)
			}
			@ 
			
			Como se puede observar es el mismo código solo que en uno se trabajan con las frecuencias absolutas y en el otro con las relativas. Comprobamos su funcionamiento:
			
			{\small
			<<>>=
			frecuencia_abs_acum = acum_absolute_freq(distancias)
			frecuencia_abs_acum
			
			frecuencia_rel_acum = acum_relative_freq(distancias)
			frecuencia_rel_acum
			@
			}
			
			Se puede comprobar que son correctos, ya que la frecuencia absoluta acumulada del último elemento es igual al número total de elementos (73) y la frecuencia relativa acumulada del último elemento es 1.\\
			
			Prosiguiendo con el análisis de datos, se tiene que obtener la moda del conjunto de datos. Para ello se ha elaborado una función que nos calculará este valor. Ayudándonos de las frecuencias absolutas, se pueden iterar y buscar la mayor frecuencia, cuyo elemento asociado será la moda. Se va iterando la frecuencia de cada elemento diferente de la lista y se comprueba si su frecuencia es la mayor hasta el momento. En caso de serlo, la moda temporal corresponderá a ese elemento. Así observaremos todos los elementos, devolviendo después de terminar la iteración de la lista el elemento con mayor frecuencia, la moda. El código que incluye esta funcionalidad es el siguiente:
			
			{\small
			<<>>=
			mode = function(list){
				frequencies = absolute_freq(list)
				elements = frequencies[1,]
				freq_values = frequencies[2,]
				actual_mode = 0
				actual_mode_val = 0
				for (i in 1:len(elements)){
					if (freq_values[i] > actual_mode_val){
						actual_mode_val = freq_values[i]
						actual_mode = elements[i]
					}
				}
				actual_mode
			}
			@
			}
			
			Se extrae la moda del conjunto de datos proporcionado:
			
			<<>>=
			moda = mode(distancias)
			moda
			@
		
			Se observa que la moda del conjunto de distancias es 30. Se puede comprobar que es correcto si observamos las frecuencias absolutas, ya que el elemento más que tiene es el 30 con una frecuencia absoluta de 8. Cabe destacar que en caso de haber dos o más elementos con la misma mayor frecuencia del conjunto de datos, el algoritmo devolverá el elemento de menor magnitud al iterar de menor a mayor elemento.\\
			
			El siguiente análisis que se hará es el de la mediana, que se ha visto que es el dato que divide en dos al conjunto total de datos. Para calcular este valor se tendrá que observar la paridad del número total de datos. Para saber si $n$ es par, basta con calcular $n\pmod{2}$. Si $n \equiv 0 \pmod{2}$ será par, y si $n\pmod{2} \equiv 1$, será impar. \\
			
			En caso de tener un número de elementos par, se cogerá de la lista ordenada el elemento $\frac{n}{2}$ y el elemento $\frac{n}{2} + 1$, sumarlos y dividir entre dos. En caso de tener un número de elementos impar directamente tendremos que coger el elemento $\frac{n+1}{2}$.\\
			
			Se han englobado estos cálculos en una función, donde se comprueba si se está ante un número de elementos par o impar, y se accede a los elementos correspondientes. La función es la siguiente:
			
			<<>>=
			median_value = function(list){
				n = len(list)
				ordered_list = bubble(list)
				if (n%%2 == 0){
					median = (ordered_list[n/2] + ordered_list[(n/2)+1]) / 2
				}
				else{
					median = ordered_list[(n+1)/2]
				}
				median
			}
			@
			
			Comprobación del valor de la mediana del conjunto de datos:
			
			<<>>=
			mediana = median(distancias)
			mediana
			@
			
			Se observa que el valor medio es 20. Esto es correcto, ya que si se observa el conjunto ordenado, se ve que existen 73 datos, luego $\tilde{x}$ será el elemento $x_{\frac{73+1}{2}} = x_{37} = 20$, el valor obtenido como mediana. \\
			
			Tras haber codificado las medidas de tendencia central, se estudiarán dos medidas de dispersión. La primera de las medidas que se van a calcular es la desviación típica. Para ello se ha codificado la siguiente función:
			
			<<>>=
			standard_dev = function(list){
				mean = mean(list)
				n = len(list)
				add = 0
				for (i in 1:n){
					add = add + ((list[i] - mean)^2)
				}
				sqrt(add/n)
			}

			@
			
			Como se puede observar, la función consiste en ir sumando las diferencias entre cada dato y la media de todos ellos elevadas al cuadrado, $(x_i - \bar{x})$. El bucle \texttt{for} de la función es el encargado de realizar esta tarea. Tras ello, se divide el resultado entre el número total de datos $n$, y se realiza la raíz cuadrada de la medida obtenida. La desviación típica, por tanto, obedece a la fórmula: 
			
			$$
			s = \sqrt{\frac{\displaystyle\sum_{i=1}^n (x_i-\bar{x})^2}{n}}
			$$
			
			La desviación típica del conjunto de datos será la siguiente:
			
			<<>>=
			desviacion = standard_dev(distancias)
			desviacion
			@
			
			La segunda y última medida de dispersión que se estudiará es la varianza, que en el fondo, no es más que elevar la desviación típica al cuadrado.
			
			$$
			s^2 = \frac{\displaystyle\sum_{i=1}^n (x_i-\bar{x})^2}{n}
			$$
			
			<<>>=
			variance = function(list){
				dev = standard_dev(list)
				var = dev^2
				var
			}
			@
			
			Con esta función, se calcula la varianza del conjunto de datos:
			
			<<>>=
			varianza = variance(distancias)
			varianza
			@
			
			Terminadas las medidas de dispersión, se procede a calcular los cuantiles. Para calcular los cuantiles se tendrá que definir, además de la lista de la que se quiere calcular el valor, de c (que es ...). Esto último tendrá que corresponder a un valor entre 0 y 1 en función de $c$. Así, si se introduce por parámetro un $c$ que no es válido se devolverá \texttt{NULL}, ya que no se puede hacer el cálculo. En caso de haber introducido un $c$ válido se observan dos casos.
			
			\begin{itemize}
				\item Si $nc \in \mathbb{N}$ (siendo $n$ el número total de elementos), se calculará $\frac{x_{nc}+x_{nc+1}}{2}$. 
				\item Si $nc \not \in \mathbb{N}$ (siendo $n$ el número total de elementos), se deberá coger el elemento $\left\lfloor nc \right\rfloor + 1 $ o $ \left\lceil nc \right\rceil$. 
			\end{itemize}
			
			Con estos cálculos se codifica una función que calcula los cuantiles. La función es la siguiente:
			
			<<>>=
			quant = function(list, c){
				ordered_list = bubble(list)
				n = len(list)
				if (c < 0 | c > 1){
					quant = NULL
				}
				else{
					if((n*c)%%1 == 0){
						quant = (ordered_list[(n*c)] +
						 ordered_list[(n*c) + 1]) / 2
					}
					else {
						int_prod = floor(n*c)
						quant = ordered_list[int_prod + 1]
					}
				}
				quant
			}	
			
			@
			
			Para poder comprobar si $nc \in \mathbb{N}$,  se calcula $nc \pmod{1}$, pues $\forall a \in \mathbb{Z}, a \equiv 0 \pmod{1}$. Además, se garantiza que $nc \in \mathbb{Z} \rightarrow nc \in \mathbb{N}$. Esto es por dos razones fundamentales:
			
			\begin{itemize}
				\item Siempre se cumplirá que $n > 0$. 
				\item Siempre se cumplirá que $0 < c < 1$. 
			\end{itemize}
			
			En caso de que $nc \not \in \mathbb{N}$ se trabajará con $\left\lfloor nc \right\rfloor$. Para calcularla se ha hecho uso de la función \texttt{floor} perteneciente al paquete \texttt{base}. Esta función recoge como parámetro un número y devuelve su aproximación en número entero redondeado hacia abajo. Por ejemplo, si aplicamos esta función a $4.99$, devolverá 4, pues $\left\lfloor4.99\right\rfloor = 4$.\\
			
			Con esta función se podrán calcular cuantiles, entre los que se incluyen cuartiles, deciles, percentiles, etc. Para probar la función se calculan los tres cuartiles $\frac{1}{4}, \frac{2}{4}$ y $\frac{3}{4}$.
			
			<<>>=
			cuartil1 = quant(distancias,0.25)
			cuartil2 = quant(distancias,0.5)
			cuartil3 = quant(distancias,0.75)
			cuartilerr = quant(distancias, -0.2)
			
			cuartil1
			cuartil2
			cuartil3
			cuartilerr
			@
			
			Se observa que los valores de $\tilde{x}_{\frac{1}{4}}, \tilde{x}_{\frac{2}{4}}, \tilde{x}_{\frac{3}{4}}$ son $8.1, 20$ y $28$. Además, se ha probado a meter un valor de $c$ no válido y verificamos que efectivamente se devuelve \texttt{NULL}, ya que ese cálculo no sería lógicamente correcto. También se comprueba que $\tilde{x}_{\frac{2}{4}} = \tilde{x}$ que se ha calculado previamente. Ambos valores deben coincidir ya que hacen referencia al mismo elemento que realiza la misma división de los datos.
			
		\section{Asociación}
		
			\begin{exercise}
				El segundo conjunto de datos, que se empleará para realizar el análisis de asociación, estará formado por las siguientes conjuntos de extras incluidos en 8 ventas de coches: \{X, C, N, B\}, \{X, T, B, C\}, \{N, C, X\}, \{N, T, X, B\}, \{X, C, B\}, \{N\}, \{X, B, C\}, \{T, A\}. Donde: \{X: Faros de Xenon, A: Alarma, T: Techo Solar, N: Navegador, B: Bluetooth, C: Control de Velocidad\}, son los extras que se pueden incluir en cada coche.
			\end{exercise}
			
			Para realizar el algoritmo $apriori$ es necesario programar previamente algunas funciones auxiliares que ayudarán a trabajar con conjuntos. Las funciones necesarias en este caso son la unión y la diferencia de conjuntos. La unión de dos conjuntos $A \cup B$ resulta en un nuevo conjunto que contiene todos los elementos de $A$ y todos los elementos de $B$ que no están en $A$. Por otro lado, la diferencia de dos conjuntos $A \backslash B$ da como resultado un nuevo conjunto que contiene todos los elementos de $A$ que no formen parte de $B$. Como función auxiliar también ser hará uso de la función \texttt{len}, explicada en la \Cref{sec:descrip_auto}.
			
			<<>>=
			union = function(c1, c2) {
				if (len(c1) == 0) {
					c2
				} else if (is.element(c1[1], c2)) {
					union(c1[-1], c2)
				} else {
					union(c1[-1], append(c2, c1[1]))
				}
			}
			
			dif = function(c1, c2) {
				res = c()
				for (element in c1) {
					if (!(element %in% c2)) {
						res = append(res, element)
					}
				}
				res
			}
			@
			
			Tras codificar las funciones auxiliares sobre conjuntos, se va a proceder a programar el algoritmo. Para ello, lo primero que se va a realizar es la creación de una función que cuente las apariciones de una serie de elementos en los sucesos. Se sumará uno al contador cuando todos los elementos aparezcan en el mismo suceso. La función es la siguiente:
			
			<<>>=
			count_appearance = function(table, elements) {
				count = 0
				for (i in 1:len(table[,1])) {
					acum = 1
					for (element in elements) {
						acum = (table[i,element]) & acum
					}
					count = count + acum
				}
				count
			}
			@
			
			Como se puede observar, el código consiste en iterar cada uno de los sucesos, y para cada uno de ellos, se va realizando la operación lógica $and$
			
			<<>>=
			support = function(table, elements) {
				count_appearance(table, elements) / len(table[,1])
			}
			
			support_clasif = function(table, ocurrences, s) {
				valid_ocurrences = c()
				for (ocurrence in ocurrences) {
					support_oc = support(table, ocurrence)
					if (support_oc >= s) {
						valid_ocurrences = append(valid_ocurrences, ocurrence)
					}
				}
				valid_ocurrences	
			}
			@
			
			
			
			<<>>=
			create_comb = function(table, clasif, s) {
				combinations = c()
				dim = 2
				next_dim = TRUE
				while (dim <= len(clasif) & next_dim == TRUE) {
					next_dim = FALSE
					comb = unlist(lapply(dim, function(m) {
						combn(clasif, m=m, simplify=TRUE)
						}), recursive=FALSE)
					
					for (j in seq(1, len(comb), by=dim)) {
						add = c()
						for (k in j:(j+dim-1)) {
							add = append(add, comb[k])
						}
						if (support(table, add) >= s) {
							next_dim = TRUE
							combinations = append(combinations, list(add))
						}
					}
					dim = dim+1
				}
				combinations
			}
			@
			
			
			
			<<>>=
			confidence = function(table, left, right) {
				count_appearance(table, union(left, right)) /
					count_appearance(table, left)
			}
			
			get_asotiations = function(table, comb, c) {
				kMax = len(comb[len(comb)][[1]])
				listLeft = list()
				listRight = list()
				
				for (i in 2:kMax) {
				
					split = Filter(function(x) length(x)==i, comb)
					
					for (j in 1:len(split)) {
					
						for (k in 1:(i-1)) {
						
							leftSides = lapply(k, function(m) {
								combn(split[j][[1]], m=m, simplify=TRUE)})
							
							df = do.call(rbind.data.frame, leftSides)
							
							for (n in 1:len(df[1,])) {
							
								all = split[j][[1]]
								
								left = df[,n]
								
								right = dif(split[j][[1]], df[,n])
								
								if (confidence(table, left, right) >= c) {
								
									listLeft = append(listLeft , list(left))
									listRight = append(listRight , list(right))
								
								}
							}
						}
					}
				}
				data.frame(left = I(listLeft), right = I(listRight))
			}
			@
			
			
			
			<<>>=
			getElements = function(data) {
				elements = c()
				for (i in 1:len(data)) {
					elements = union(elements, data[[i]])
				}
				elements
			}
			
			getTable = function(data, elements) {
				nCol = len(elements)
				nRow = len(data)
				table = data.frame(matrix(0, ncol = nCol, nrow = nRow,
				dimnames = list(1:nRow, elements)))
				
				for (i in 1:nRow) {
					for (j in 1:len(data[[i]])) {
						table[i, data[[i]][j]] = 1
					}
				}
				table
			}
			@
			
			
			<<>>=
			apriori = function(data, s, c) {
			
				elements = getElements(data)
				
				table = getTable(data, elements)
				
				soporte_clasif = support_clasif(table, elements, s)
				
				combinations = create_comb(table, soporte_clasif, s)
				
				if (len(combinations) > 0) {
				
					conf = get_asotiations(table, combinations, c)
					print(conf)
				
				} else {
					print("No hay ninguna combinación que pase el soporte")
				}
			}
			
			data = list(
			c("X", "C", "N", "B"),
			c("X", "T", "B", "C"),
			c("N", "C", "X"),
			c("N", "T", "X", "B"),
			c("X", "C", "B"),
			c("N"),
			c("X", "B", "C"),
			c("T", "A"))
			
			data2 = list(
			c("Pan", "Agua", "Leche", "Naranjas"),
			c("Pan", "Agua", "Café", "Leche"),
			c("Pan", "Agua", "Leche"),
			c("Pan", "Café", "Leche"),
			c("Pan", "Agua"),
			c("Leche"))
			
			apriori(data, 0.4, 0.9)
			
			@
			
		
		\section{Detección de datos anómalos}
		
			\subsection{Técnicas estadísticas}
			
				\begin{exercise}
					El tercer conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas con base estadística, estará formado por los siguientes 10 valores de velocidades de respuesta y temperaturas normalizadas de un microprocesador \{Velocidad, Temperatura\}: \{10, 7.46; 8, 6.77; 13, 12.74; 9, 7.11; 11, 7.81; 14, 8.84; 6, 6.08; 4, 5.39; 12, 8.15; 7, 6.42; 5, 5.73\}. Aplicar las medidas de ordenación a la velocidad y las de dispersión a la temperatura.
				\end{exercise}
				
				Como se ha visto previamente, el cálculo de \textit{outliers} por medio de técnicas con base estadística no proporcionaban los mismos resultados que los vistos en clase, ya que hay ciertos cálculos (como el de los cuartiles o la desviación) están realizados de forma diferente a como se ha estudiado; y esto implica un error que se propaga al cálculo de los intervalos para valores atípicos y por consecuente al resultado final.  Si recordamos, en la \Cref{sec:descrip_auto}, se han realizado nuestras propias funciones que proporcionan los resultados correctos a los cálculos. Es por ello que, en base a estas funciones, se van a realizar los algoritmos correspondientes:\\
				
				En primer lugar se van a introducir los datos. Para ello se hará tal y se ha visto previamente, con la función \texttt{matrix}, de tal forma que esta tenga dos columnas (una para \texttt{velocidad} y otra para \texttt{temperatura}) y tantas filas como entradas de datos se tengan. Tras ello, se pasa esta matriz a un \texttt{dataframe} para operar sobre los datos de una forma más cómoda. El resultado es el siguiente: 
				
				<<>>=
				muestra = t(matrix(c(10,7.46,8,6.77,13,12.74,9,7.11,11,7.81,14,8.84,6,
				6.08,4,5.39,12,8.15,7,6.42,5,5.73),
				2,11,dimnames=list(c("velocidad","temperatura"))))
				muestra=data.frame(muestra)
				
				muestra
				@
				
				Se observa que se tienen los datos dispuestos en dos columnas, una para \texttt{velocidad} y otra para \texttt{temperatura}. También se tienen 11 filas, que corresponde con el número total de parejas (\texttt{velocidad}, \texttt{temperatura}) entrantes al conjunto de datos. 
				
				\subsubsection{Medidas de ordenación (caja y bigotes)}
				
					Con los datos organizados se puede empezar a trabajar. Lo primero de todo será aplicar las medidas de ordenación a la velocidad. Esto quiere decir aplicar el algoritmo de caja y bigotes que hemos visto en la \Cref{subsub:caja_bigotes}. Primeramente, centraremos nuestra atención en la columna \texttt{velocidad}, que es la que interesa ahora:
					
					<<>>=
					muestra_velocidad = muestra$velocidad
					@
					
					Con esta línea de código se guarda la columna de velocidad, y se podrá llamar a la función que implementa el algoritmo directamente con \texttt{muestra\_velocidad}. Una vez tenemos está todo listo veamos el código del algoritmo.
					
					{\tiny
					<<>>=
					boxNmustaches = function(sample, d, details = FALSE){
						outliers = c()
						if(details){
							print("->PASO 1: DETERMINACIÓN DEL GRADO DE OUTLIER")
							cat("Se ha introducido un grado de outlier d = ",d,"\n\n")
						}
						cuart1 = quant(sample, 0.25)
						cuart3 = quant(sample, 0.75)
						if (details){
							print("->PASO 2: CÁLCULO DE LOS CUARTILES 1 Y 3")
							cat("El cuartil 1 es ",cuart1, " y el cuartil 3 es ", cuart3,"\n\n")
						}
						lim_inf = cuart1 - (d*(cuart3-cuart1))
						lim_sup = cuart3 + (d*(cuart3-cuart1))
						if (details){
							print("->PASO 3: CÁLCULO DE LOS LÍMITES DEL INTERVALO PARA VALORES ATÍPICOS")
							cat("Fórmula -> (Q1 - d*(Q3-Q1), Q3 + d*(Q3-Q1))\n")
							cat("El intervalo para los valores atípicos es: (",lim_inf,", ",lim_sup,")\n\n")
						}
						if(details){
							print("->PASO 4: IDENTIFICACIÓN DE OUTLIERS")
							cat("Los outliers serán aquellos valores que no están en el intervalo anterior\n")
						}
						for (i in 1:len(sample)){
							if(sample[i] < lim_inf || sample[i] > lim_sup){
								outliers = append(outliers, i)
								if(details){
									cat("El punto ",i," con valor ",sample[i]," es un outlier\n")
								}
							}
						}
						if(len(outliers) == 0){
							cat("No hay outliers")
						}
					outliers
					}
					@
					}
					
					Para comenzar, la función recibe los siguientes parámetros:
					%REVISADO HASTA AQUÍ%
					\begin{itemize}
						\item \texttt{sample}: El data frame con los datos correspondientes. En este caso, \texttt{muestra\_velocidad}. 
						\item \texttt{d}: El grado de \textit{outlier} a partir del cual un dato se considera anómalo. Servirá para calcular el intervalo para valores atípicos.
						\item \texttt{details}: Es un parámetro que por defecto estará a \texttt{FALSE}, y que servirá para que el usuario indique si quiere una salida detallada o sencilla. Con salida sencilla nos referimos a una lista con los índices de los puntos que se han evaluado como \textit{outliers}, mientras que con salida detallada se devolverá esto mismo además de una serie de mensajes por pantalla donde se detalla cada paso y lo que se hace en él, así como los resultados parciales que vamos obteniendo.
					\end{itemize}
					
					Vamos a centrarnos en la salida detallada para ir explicando poco a poco el algoritmo.\\
					
					\begin{itemize}
						\item \texttt{Paso 1}: En este paso determinamos el grado de outlier el cual es elegido arbitrariamente por el usuario. Esta parte del algoritmo no es más que reescribir el parámetro \texttt{d} que ha introducido a la hora de llamar a la función. Además, hacemos uso de \texttt{cat}, función contenida en el paquete \texttt{base} y que permite realizar salidas por pantalla con argumentos. En nuestro caso, queremos imprimir por pantalla, además de un mensaje, el valor de \texttt{d} en la misma línea. Para evitar hacer dos \texttt{print}, usamos esta función que pasará el valor de \texttt{d} a la cadena de texto que se imprimirá.
						
						\item \texttt{Paso 2}: En este paso vamos a calcular los cuartiles 1 y 3 (0.25 y 0.75) para posteriormente utilizarlos en el cálculo del intervalo para valores atípicos. Observamos que hacemos uso de la función \texttt{quant} que habíamos definido en la sección 2.1. Además, si el usuario lo desea, se imprime por pantalla el valor de ambos.
						
						\item \texttt{Paso 3}: Una vez calculados los cuartiles vamos a calcular el intervalo que nos permitirá clasificar los \textit{outliers}. Para ello calculamos \texttt{lim\_inf} y \texttt{lim\_sup} que serán los límites inferior y superior respectivamente, ambos mediante la fórmula que hemos visto en la sección 1.3. El hecho de haber utilizado nuestra función \texttt{quant} para el cálculo de los cuartiles permite que el intervalo sea ahora el que nos salió en clase de teoría.
						
						\texttt{Paso 4}: Por último, recorremos todos los datos y buscamos aquellos que estén por debajo del límite inferior o por encima del límite superior, ya que al no estar comprendido en el intervalo se consideran datos anómalos. Además, añadimos a una lista \texttt{outliers} (previamente vacía) estas anomalías para posteriormente devolverlas.\\
					\end{itemize}
					
					Con este algoritmo vamos a resolver el ejercicio. Vamos a llamar a la función \texttt{boxNmustaches} con \texttt{muestra\_velocidad} y un valor $d = 1.5$.\\
					
					<<>>=
					anomalias_vel = boxNmustaches(muestra_velocidad, 1.5, TRUE)
					@
					
					Observamos cómo se informa al usuario del grado de \textit{outlier} que ha introducido, de los valores de los cuartiles 1 y 3, de cómo se calcula el intervalo para valores atípicos y de todos aquellos \textit{outliers} que se han encontrado. En este ejemplo concreto no hay \textit{outliers} ya que todos los valores se encuentran dentro del intervalo establecido. Si se quisiera acceder a la lista que contiene todos los \textit{outliers} bastaría con acceder en este ejemplo a \texttt{anomalias\_vel}.\\
					
					\textbf{\large{Medidas de dispersión}}\\
					
					En este segundo apartado del ejercicio vamos a detectar anomalías, esta vez sobre la columna de temperatura y aplicando medidas de dispersión. El cálculo del intervalo se realiza esta vez con la media aritmética y la desviación típica. Como hemos ido viendo, el cálculo de la desviación típica mediante la función \texttt{sd} es diferente que el que hemos visto en teoría. Por ello, podemos aplicar la función \texttt{standard\_dev} que hemos elaborado en la sección 1.3 y que nos da el valor que hemos visto en clase de teoría. Primeramente vamos a guardarnos la columna de temperaturas para luego trabajar mejor sobre ella.
					
					<<>>=
					muestra_temp = muestra$temperatura
					@
					
					Ya tenemos los datos de temperatura, así que solo queda llamar a la función que implementa este algoritmo. Es bastante similar a la función anterior de \texttt{boxNmustaches}, solo que ahora en vez de calcular cuartiles calculamos la media aritmética y la desviación típica; y la fórmula del intervalo para valores atípicos también cambia, tal y como hemos visto en la sección 1.3. La función que implementa el algoritmo es la siguiente:
					
					<<>>=
					dispersed_outliers = function(sample, d, details = FALSE){
						outliers = c()
						if(details){
							print("->PASO 1: DETERMINACIÓN DEL GRADO DE OUTLIER")
							cat("Se ha introducido un grado de outlier d = ",d,"\n\n")
						}
						mean_sample = mean(sample)
						if (details){
							print("->PASO 2: CÁLCULO DE LA MEDIA ARITMÉTICA")
							cat("La media aritmética es ", mean_sample, "\n\n")
						}
						dev_sample = standard_dev(sample)
						if (details){
							print("->PASO 3: CÁLCULO DE LA DESVIACIÓN TÍPICA")
							cat("La desviación típica es ", dev_sample, "\n\n")
						}
						lim_inf = mean_sample - (d*dev_sample)
						lim_sup = mean_sample + (d*dev_sample)
						if (details){
							print("->PASO 4: CÁLCULO DE LOS LÍMITES DEL INTERVALO PARA VALORES ATÍPICOS")
							cat("Fórmula -> (Media - d*DesviaciónTípica, Media + d*DesviaciónTípica)\n")
							cat("El intervalo para los valores atípicos es: (",lim_inf,", ",lim_sup,")\n\n")
						}
						if(details){
							print("->PASO 5: IDENTIFICACIÓN DE OUTLIERS")
							cat("Los outliers serán aquellos valores que no están en el intervalo anterior\n")
						}
						for (i in 1:len(sample)){
							if(sample[i] < lim_inf || sample[i] > lim_sup){
								outliers = append(outliers, i)
								if(details){
									cat("El punto ",i," con valor ",sample[i]," es un outlier\n")
								}
							}
						}
						if(len(outliers) == 0){
							cat("No hay outliers")
						}
						outliers
					}
					@
					
					Como podemos ver el código es prácticamente igual. Se pasan los mismos parámetros que en el algoritmo anterior. El primer paso recuerda al usuario el grado de dispersión que ha introducido y el segundo  y tercer paso calculan la media y la desviación típica con nuestras funciones que lo hacen como hemos visto en teoría. El cuarto paso calcula los límites del intervalo para valores atípicos haciendo uso de la media y la desviación típica previamente calculadas y con la fórmula que vimos en la sección 1.3, y finalmente se recorren todos los datos en busca de los valores que no están dentro del intervalo calculado.\\
					
					Al igual que en el algoritmo anterior, se devolverá una lista con los puntos que son \textit{outliers} y se podrá elegir entre una salida detallada con mensajes por pantalla del proceso o una salida limitada a la devolución de la lista de \textit{outliers}.\\
					
					Vamos a probar nuestro algoritmo con la temperatura y un grado de dispersión $d=2$:
					
					<<>>=
					anomalias_temp = dispersed_outliers(muestra_temp,2,TRUE)
					@
					
					Observamos cómo se ha ido haciendo todo el proceso (porque hemos puesto que queremos una salida detallada) y vemos que al final se ha encontrado una anomalía en el punto 3 cuyo valor es 12.74, el cual se encuentra fuera del intervalo, por lo que es considerado un \textit{outlier}.\\
					
					Si quisiéramos acceder a la lista de los puntos que son \textit{outliers} bastaría con acceder a la variable a la que hemos igualado la llamada de la función. En este caso habría que acceder a \texttt{anomalias\_temp}.
					
					<<>>=
					anomalias_temp
					@
					
					Y efectivamente tenemos una lista con un 3, el punto que hemos visto que era un \textit{outlier}.\\
					
			\subsection{Proximidad y densidad}
			
				\begin{exercise}
					El cuarto conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas basadas en la proximidad y en la densidad, estará formado por el número de Mujeres y Hombres inscritos en una serie de cinco seminarios que se han impartido sobre biología. Los datos son: \{Mujeres, Hombres\}: 1. \{9, 9\}; 2. \{9, 7\}; 3. \{11, 11\}; 4. \{2, 1\}; 5. \{11, 9\}.
				\end{exercise}
					
					Para resolver este ejercicio de otra forma se empleará el algoritmo LOF o Local Outlier Factor. Este se basa en la densidades y la distancia Manhattan. Esta se define de la siguiente forma para los puntos de la muestra: 
					
					$$
					\dt(x_i, x_j) = |x_{i_1}-x_{j_1}| + |x_{i_2}-x_{j_2}|
					$$
					
					Esta distancia se calcula en R mediante la función observada a continuación. Para ello se itera sobre las diferentes componentes de los puntos y se calcula su diferencia en valor absoluto, es decir, se generaliza de la siguiente manera: 
					
					$$
					\dt(x_i, x_j) = \sum_{i=1}^n |x_i-x_j|
					$$
					
					<<>>=
					manhattan_distance = function(p1, p2) {
						add = 0
						for(i in 1:len(p1)){
							add = add + abs(p1[i] - p2[i])
						}
						add
					}
					@
					
					Como se necesita calcular la distancia entre cada posible par de puntos, se organizan estos datos en una matriz (representada por un dataframe) haciendo uso de la función anterior. Se tiene en cuenta que $\dt(x_i, x_j) = \dt(x_j, x_i)$ y se recoge en la siguiente función. 
					
					<<>>=
					create_distance_matrix = function(df){
						empty_matrix = matrix(ncol = len(df[,1]), nrow = len(df[,1]))
						distances = data.frame(empty_matrix)
						for (i in 1:len(df[,1])){
							p_dists = c()
							for (j in i:len(df[,1])){
								dist = manhattan_distance(df[i,], df[j,])
								distances[i,j] = dist
								distances[j,i] = dist
							}
							distances = rbind(distances, p_dists)
						}
						distances
					}
					@
					
					Ahora se necesitará ordenar las distancias a los puntos para construir el conjunto $N(x_i, k)$. Para ello se hará uso del algoritmo de ordenación de la burbuja explicado en ejercicios anteriores, pero se le realizarán una serie de modificaciones para adaptarlo a este caso. Esto se realiza con la función que se presenta a continuación. 
					
					<<>>=
					bubble_LOF = function(d_list, p_list){
						n = len(d_list)
						for (i in 2:n){
							for (j in 1:(n-1)){
								if (d_list[j] > d_list[j+1]){
									temp = d_list[j]
									d_list[j] = d_list[j+1]
									d_list[j+1] = temp
									
									temp = p_list[j]
									p_list[j] = p_list[j+1]
									p_list[j+1] = temp
								}
							}
						}
						data.frame("dis"=d_list, "poi"=p_list)
					}
					@
					
					Esta función recibe los parámetros \texttt{d\_list} y \texttt{p\_list}, que representan las listas de las distancias y de los punto, respectivamente. En realidad, realiza lo mismo que el algoritmo visto en otros ejercicios, ordenando la lista \texttt{d\_list}, pero aplica los cambios en las sucesivas iteraciones también en la lista \texttt{p\_list}. Se devolverán dos columnas, una con listas de puntos, y otra con listas a las distancias a dichos puntos, ordenadas de forma ascendente. Estas listas serán paralelas (compartirán índices), y representarán al mismo elemento. \\
					
					Una vez ordenadas las distancias y los puntos, deberán ser calculados los conjuntos $N(x_i, k)$. Por su propia definición debemos mirar (al menos) hasta el $k-$vecino más cercano al punto, y añadir estos, y en caso de que los sucesivos $k+\alpha$ compartan distancia con el $k$, entonces también deberán ser añadidos. Esto se recoge en la siguiente función: 
					
					{\small
					<<>>=
					get_n_set = function(df, k) {
						d_list = list()
						p_list = list()
						
						distance_matrix = create_distance_matrix(df)
						
						for (column in 1:len(distance_matrix[1,])){
							ordered_column = tail(bubble_LOF(distance_matrix[,column],
							 1:ncol(distance_matrix)), ncol(distance_matrix)-1)
							
							k_aux = k
							
							while(k_aux < nrow(ordered_column) & 
							ordered_column[k_aux, "dis"] == ordered_column[k_aux+1, "dis"]) {
								k_aux = k_aux + 1
							}
							
							d_list = append(d_list, list(head(ordered_column[,"dis"], k_aux)))
							p_list = append(p_list, list(head(ordered_column[,"poi"], k_aux)))
						}
						data.frame(dis = I(d_list), poi = I(p_list))
					}
					@
					}
					
					En esta función se seleccionan los primeros $k-$vecinos. Obviamente, en primer lugar se eliminan los elementos $\dt(x_i, x_i)$, pues siempre será igual a 0. Esto se logra con la función \texttt{tail} del paquete \texttt{utils} y que permite conservar el resto de distancias. Una vez seleccionados los $k$ más cercanos, se va avanzado sobre el resto de vecinos y se revisa si el siguiente al último debe añadirse debido a que sean iguales, y así sucesivamente hasta encontrar una pareja de distancias diferentes, o no tener más vecinos. Se utiliza la función \texttt{head} del paquete \texttt{utils} para obtener el conjunto $N(x_i, k)$ y se devuelven en un dataframe. \\
					
					El siguiente paso es calcular la densidad de cada punto. Esta se realiza mediante la siguiente expresión: 
					
					$$
					\ds(x_i, K) = \frac{|N(x_i, K)|}{\displaystyle\sum_{x_j \in N(x_i, K)}\dt(x_i, x_j)}
					$$
					
					En el código queda representado mediante la siguiente función. Basta con acceder a los datos correctos del dataframe devuelto por la función \texttt{get\_n\_set}. Esta función devuelve una columna con las densidades de cada punto, la fila $i-$ésima almacena $\ds(x_i, k)$. 
					
					<<>>=
					add_list = function(l) {
						add = 0
						for (i in 1:len(l)) {
							add = add + l[i]
						}
						add
					}
					@
					
					{\small
					<<>>=
					get_densities = function(n_set) {
						densities = c()
						for (i in 1:len(n_set[,1])) {
							densities = append(densities, len(n_set[i,1][[1]]) /
							 add_list(n_set[i,1][[1]]))
						}
						densities
					}
					@
					}
					
					Se hace uso de la función auxiliar \texttt{add\_list}, que devuelve la suma de los elementos de una lista. En este caso $\sum_{j=1}^{|N|} \dt(x_i, x_j)$. \\
					
					A continuación, deberán calcularse las densidades relativas medias de cada punto, pudiendo identificar mediante estas los outliers. Esta se calcula mediante la siguiente expresión. 
					
					$$
					\drm(x_i, K) = \frac{\ds(x_i, K) \cdot |N(x_i, K)|}{\displaystyle\sum_{x_j \in N(x_i, K)}\ds(x_j, K)}
					$$
					
					En el código se calcula mediante la siguiente función, que representa la ecuación mostrada, pero adaptada a las estructuras de datos utilizadas durante el resto del algoritmo. Al igual que hacía \texttt{get\_densities}, se devuelve una columna con los valores de $\drm(x_i, k)$. 
					
					<<>>=
					get_drm = function(n_set) {
						drms = c()
						for (i in 1:len(n_set[,1])) {
							add_densities = 0
							
							points = n_set[i, "poi"][[1]]
							for (j in 1:len(points)) {
								add_densities = add_densities + 
									n_set[points[j], "densities"]
							}
						
							drm = n_set[i, "densities"] * len(points) / add_densities
							drms = append(drms, drm)
						}
						drms
					}
					@
					
					Finalmente, se unen todos los pasos comentados en la función \texttt{lof}. Esta muestra un dataframe con los parámetros que se han ido calculando. Para ello se emplea la función \texttt{cbind} para ir construyendo dicho dataframe. 
					
					<<>>=
					lof = function(muestra, k) {
						n_set = get_n_set(muestra, k)
						
						densities = get_densities(n_set)
						n_set = cbind(n_set, densities)
						
						drms = get_drm(n_set)
						
						n_set = cbind(n_set, drms)
						n_set
					}
					@
					
					Se comprueban los resultados obtenidos, dejando a juicio del analista el valor de $k$ y la selección de outlier en función de la drm. 
					
					<<>>=
					muestra = data.frame("mujeres" = c(9,9,11,2,11), "hombres" = c(9,7,11,1,9))
					(lof(muestra, 3))
					@
	
\end{document}          
