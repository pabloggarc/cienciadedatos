\documentclass[12pt]{report}

\usepackage[spanish]{babel}
\usepackage[margin=2.54cm]{geometry}
\usepackage[dvipsnames]{xcolor}
\usepackage{array, amssymb, amsthm, enumitem, fancyhdr, float, graphicx, hyperref, hologo, listings, mathtools, tikz, tikz-cd}
\usepackage[spanish, noabbrev]{cleveref}

\pagestyle{fancy}
\lhead{\footnotesize \leftmark}
\rhead{\footnotesize \rightmark}

\lstdefinestyle{estilo_pablo}{
	basicstyle = \ttfamily\footnotesize, 
	tabsize = 2, 
	commentstyle = \color{gray}, 
	keywordstyle = \color{cyan}, 
	stringstyle = \color{purple}, 
	tabsize = 1, 
	frame = tb, 
	breaklines = true, 
	showstringspaces = false, 
	numbers = left, 
	numberstyle = \footnotesize\color{gray}, 
	stepnumber = 1, 
	captionpos = b
}
\crefname{listing}{Código}{Códigos}

\title{
	\huge
	\noindent\textbf{Fundamentos de la Ciencia de Datos}\\
	
	{\Large \textit{Práctica 1}}
	\vspace{1cm}
	
	\huge
	Grado en Ingeniería Informática\\
	Universidad de Alcalá\\
	
	\vspace{1cm}
	
	\includegraphics[scale=0.075]{img/logo}
}

\author{
	Pablo García García\\
	Abel López Martínez\\
	Álvaro Jesús Martínez Parra\\
	Raúl Moratilla Núñez
}

\date{
	\large{14 de noviembre de 2023}
}

\hypersetup{
	pdftitle={Práctica 1}, 
	pdfauthor={Pablo García García, Abel López Martínez, Álvaro Jesús Martínez Parra, Raúl Moratilla Núñez}, 
	pdfsubject={Fundamentos de la Ciencia de Datos}, 
	pdfcenterwindow, 
	pdfnewwindow=true, 
	pdfkeywords={Entrega de la PL1 de laboratorio correspondiente al Curso 2023-2024}, 
	bookmarksopen=true 
}

\begin{document}
	
	\renewcommand{\chaptername}{Parte}
	\renewcommand{\lstlistingname}{Código}
	\maketitle \thispagestyle{empty}
	
	\newpage
	
	\tableofcontents
	\listoffigures
	
	\chapter*{Introducción}\addcontentsline{toc}{chapter}{Introducción}\pagestyle{plain}
	
		\section*{El lenguaje R}\addcontentsline{toc}{section}{El lenguaje R}
		
			El lenguaje R, es un software de uso gratuito comúnmente usado en tareas relacionadas con la estadística, como el análisis o visualización de datos; o en general la propia Ciencia de Datos. Para ello cuenta con una gran cantidad de paquetes y herramientas que facilitan el trabajo.  
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.15]{img/Rlogo}
				\caption{Logo del lenguaje R}
				\label{fig:logo_R}
			\end{figure}
		
			El CRAN (Comprehensive R Archive Network, \url{https://cran.r-project.org/}) es un repositorio de recursos en línea que se utiliza para facilitar la distribución, el intercambio y el acceso a una amplia gama de software y paquetes relacionados con el lenguaje de programación R. La página web de CRAN sirve como el portal central para acceder a estos recursos y ofrece una variedad de apartados y enlaces útiles para los usuarios de R. A continuación, proporcionamos una descripción de los distintos enlaces a los que se puede acceder desde la página principal del CRAN: 
			
			\begin{itemize}
				\item Mirrors: Esta sección permite a los usuarios seleccionar un espejo (mirror) cercano para descargar paquetes y recursos. Los espejos son servidores que almacenan copias de los paquetes y datos de CRAN, lo que ayuda a mejorar la velocidad de descarga y la disponibilidad de los recursos.
				
				\item What's new?: En esta sección, los usuarios pueden encontrar información sobre las últimas actualizaciones y novedades en el mundo de R y los paquetes disponibles en CRAN. Esto es útil para estar al tanto de las últimas características y mejoras.
				
				\item Search: El enlace ``Search'' permite a los usuarios buscar paquetes y recursos específicos en el repositorio de CRAN. Además, se puede utilizar la función de búsqueda avanzada del motor de búsqueda de Google.
				
				\item CRAN Team: Aquí se puede encontrar información sobre las personas y equipos que trabajan en el mantenimiento y desarrollo de CRAN. Es útil para conocer a las personas detrás de esta valiosa fuente de recursos.
				
				\item About R: Esta sección proporciona información sobre el lenguaje de programación R en general. Incluye enlaces a la página de inicio de R y a ``The R Journal'', una publicación académica relacionada con R.
				
				\item Software: Esta sección ofrece acceso a diversas fuentes y binarios relacionados con R, lo que permite a los usuarios descargar e instalar R en su sistema. También proporciona acceso a paquetes, Task Views y otros recursos.
				
				\item Documentation: Aquí los usuarios pueden encontrar documentación esencial relacionada con R. Esto incluye manuales, preguntas frecuentes (FAQs) y contribuciones de la comunidad para ayudar a los usuarios a comprender y utilizar R de manera efectiva.
			\end{itemize}
			
			En R, los paquetes son extensiones de software que contienen funciones, datos y documentación para realizar tareas específicas. Antes de utilizar un paquete, debes instalarlo y cargarlo en tu sesión de R. Algunas de las funciones más útiles para preparar los paquetes de un proyecto son:
			
			\begin{itemize}
				\item \textbf{Paquetes por defecto}: \\
				Mediante \texttt{getOption("defaultPackages")} se muestra una lista de los paquetes que se cargan automáticamente cuando inicias una sesión de R. Son los paquetes básicos que R carga por defecto. Para cambiar la lista de archivos que R carga por defecto podemos acceder a la siguiente ubicación (instalación de R por defecto):\\\texttt{C:/Program Files/R/R-4.3.1/library/base/R/RProfile}, y modificar el archivo como se observa en el \Cref{cod:rprofile}, añadiendo al vector \texttt{dp} los paquetes que deseemos. 
				
				\lstinputlisting[language = R, style = estilo_pablo, firstline = 46, lastline = 54, firstnumber = 46, caption = Modificación en fichero \texttt{Rprofile}, label = cod:rprofile]{C:/Program Files/R/R-4.3.1/library/base/R/Rprofile}
				
				\item \textbf{Instalación de paquetes}: \\
				La instalación de paquetes puede ser realizada de tres formas distintas:
				
				\begin{enumerate}[label = \textbf{\arabic*. }]
					\item \texttt{install.packages("nombre\_del\_paquete")}\\
					A esta función se le debe pasar por parámetro el nombre del paquete que se desea instalar.
					
					\item \texttt{install.packages("ubicacion\_del\_paquete", rep=NULL)}\\
					A la función también se le puede pasar por parámetros la ubicación del archivo, que recomendablemente debe estar en una carpeta temporal en ``c:/'', este archivo lo descargamos desde:\\ \url{https://cran.r-project.org/} $>$ \texttt{Packages} $>$ \texttt{Table of available packages, sorted by name} $>$ Elegimos el paquete y descargamos la versión \texttt{r-release} de la sección \texttt{Windows binaries}.
					
					\item \texttt{utils:::menuInstallPkgs()}\\
					Tras la ejecución de este comando aparecerá una ventana donde se podrá elegir el mirror desde el que se va a descargar el paquete, y tras elegir el mirror (Spain (Madrid) en nuestro caso), aparece otra ventana donde se puede elegir el paquete que se quiere instalar, tras hacer doble click, este se instalará automáticamente.
				\end{enumerate}
				
				\item \textbf{Información de un paquete}: \\
				Cuando ejecutas \texttt{library(help="nombre\_del\_paquete")}, R te mostrará información detallada sobre el paquete especificado. Esto incluye una descripción del paquete y una lista de las funciones que contiene, junto con sus descripciones.
				
				\item \textbf{Carga de paquetes}: \\
				Si ejecutas \texttt{library(nombre\_del\_paquete)} con el nombre de un paquete, R cargará el paquete en tu sesión para que puedas utilizar sus funciones y objetos.
				
				\item \textbf{Lista de paquetes instalados}: \\
				Al ejecutar \texttt{library()} sin argumentos, R te mostrará una lista de los paquetes que están actualmente cargados en tu sesión de R. Esto te permite verificar qué paquetes están disponibles para su uso.
				
				\item \textbf{Lista de paquetes cargados}: \\
				Mediante \texttt{search()} podemos ver un listado completo de los paquetes actualmente cargados en memoria.
				
			\end{itemize}
			
			A parte, es recomendable descargar y conocer a conciencia el manual y las viñetas de todos los paquetes que usemos en nuestros proyectos (disponible en la página web del CRAN).
		
		\section*{El lenguaje \LaTeX}\addcontentsline{toc}{section}{El lenguaje \LaTeX}

			Para la realización de esta práctica, se empleará el concepto de \textbf{programación literaria}, que consiste en crear un documento en el que se combine texto con código, de manera que este se pueda explicar y entender de una manera mucho más sencilla. Una forma de realizar esto con código R, es el uso del lenguaje \LaTeX{}, que es un sistema de composición de documentos enfocado al ámbito científico. Es algo similar a un lenguaje de marcas con el que poder definir la estructura de un documento, pero cuenta con la particularidad de que es un lenguaje Turing--completo, por lo que cualquier algoritmo puede ser implementado dando una mayor flexibilidad, aunque no sea su objetivo principal. Veremos ahora los pasos seguidos para su instalación. Para poder trabajar, lo mínimo que necesitaremos es un compilador de \LaTeX{}, en este caso se ha optado por la distribución \hologo{MiKTeX} que lo incluye, ya que estamos trabajando en Windows. Además, para una mayor comodidad trabajando con el código, se ha optado por el IDE \TeX{}studio, uno de los más conocidos en la comunidad. \\
			
			Una vez hemos tratado ambos lenguajes, necesitamos entender con qué tipos de extensiones se suelen trabajar para ver el proceso de integración con R (sin entrar en profundidad). Estas dependen de cómo queremos almacenar nuestro documento, o cómo están almacenadas dependencias de estos, como por ejemplo, imágenes. Esta tarea se realiza usando un compilador u otro. \\
			
			Para ello nos fijaremos en la \Cref{fig:extensiones}. Por ahora nos quedaremos con las extensiones que trabajaremos más a menudo, que serán \texttt{.Rnw}, \texttt{.tex}, y \texttt{.pdf}. La primera de ellas representan los archivos que tienen código \LaTeX{} y R ``mezclado'', la segunda aquellos que contienen código \LaTeX{} puro, y la última nuestro documento final. \\
			
			\begin{figure}[H]
				\centering
				\begin{tikzcd}
					& \texttt{.Rnw} \arrow[d] & \\
					& \texttt{.tex} \arrow[ld] \arrow[rd] \arrow[dd] & \\
					\texttt{.dvi} \arrow[rr] \arrow[rd] & & \texttt{.ps} \arrow[ld] \\
					& \texttt{.pdf} &               
				\end{tikzcd}
				\caption{Esquema de extensiones en \LaTeX}
				\label{fig:extensiones}
			\end{figure}
			
			Existen dos herramientas que nos permiten trabajar con archivos \texttt{.Rnw}, estas son Sweave y Knitr. A pesar de que en la asignatura ha sido propuesta la primera de ellas, optaremos por la segunda, pues existieron diversos errores al compilar archivos con esta, y al ser más antigua, los documentos finales tenían menos calidad. Knitr nos ofrece mayor calidad y un mejor formato en el código fuente R mostrado. Para instalarla basta con escribir \texttt{install.packages('knitr')} en una consola de R. Sweave viene ya por defecto con \texttt{utils}. \\
			
			Por último, se explicará cómo hemos agilizado el proceso de trabajo con Knitr y \TeX{}Studio. Lo primero será hacer que R cargue por defecto Knitr, para ello modificaremos el archivo \texttt{Rprofile} en \texttt{libray/base/R} dentro de la carpeta de instalación de R, añadiendo \texttt{knitr} al resto de paquetes que carga por defecto. Una vez hecho esto, iremos a la configuración de \TeX{}Studio, y aquí a \textit{Compilar}. En la zona \textit{Órdenes de usuario}, crearemos una nueva tal y como se ve en la \Cref{fig:orden}, de manera que le digamos dónde están los binarios de R, para que pueda crear un fichero \texttt{.tex}, y posteriormente invocar a nuestro compilador, para obtener nuestro documento en \texttt{.pdf}. \TeX{}Studio se encargará de reemplazar el símbolo \% por el nombre del archivo que le ordenamos compilar. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.7]{img/o_usuario}
				\caption{Creación de orden de usuario}
				\label{fig:orden}
			\end{figure}
			
			Ahora basta modificar el botón verde del IDE para que en vez de invocar al compilador \hologo{pdfLaTeX}, lleve a cabo la instrucción que le hemos dado. Para ello volveremos al menú de compilación en el que nos ubicábamos previamente, y observaremos la sección de \textit{Meta-Órdenes}. Modificaremos el valor del campo \textit{Compilador por defecto}, escribiendo \texttt{txs:///knitr} para que se ejecute la orden que previamente hemos creado, o podemos hacerlo de manera gráfica como se observa en la \Cref{fig:comp}. Ahora bastará pulsar el botón verde o F5 para ver a nuestra izquierda el código de nuestro documento, y a la derecha actualizado, el documento PDF final. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.7]{img/compilacion}
				\caption{Modificación de compilación}
				\label{fig:comp}
			\end{figure}
			
			Por último, para llevar un mejor control de versiones del proyecto, y de coordinación entre los miembros del grupo, se usará un repositorio de GitHub. Añadiremos un archivo \texttt{.gitignore} para no cargar en el repositorio los archivos temporales generados durante la compilación. Otra alternativa que se podría haber usado, es usar Overleaf (aquí usaríamos la extensión \texttt{.Rtex} en vez de \texttt{.Rnw}), ya que no sería necesaria la instalación de ningún software, y también trabaja con Knitr. Sin embargo, la integración de GitHub en Overleaf es de pago, por lo que optamos por usar la configuración explicada hasta el momento, para poder tener un mejor control de versiones sin coste alguno. \\
			
			Por último, mencionar que al igual que R posee su repositorio de paquetes (que ya hemos visto que incluye más cosas) llamado CRAN, \LaTeX{} que en realidad es ``un subconjunto'' del lenguaje \TeX{}, también tiene su propio portal llamado CTAN o Comprehensive \TeX{} Archive Network (\url{https://www.ctan.org/}) de donde se descargan los paquetes y otros materiales para el lenguaje. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[scale = 0.5]{img/ctan_lion}
				\caption{Mascota de \TeX{} y el CTAN}
				\label{fig:leon}
			\end{figure}
			
	\chapter{Ejercicios guiados}\pagestyle{fancy}
	
		En esta primera parte de esta práctica, repetirán los ejercicios explicados y realizados por el profesor en las clases de laboratorio, utilizando los mismos procedimientos vistos plasmándolos en este documento. 
	
		\section{Descripción de los datos}
		
			``\textit{El primer conjunto de datos, que se empleará para realizar el análisis de descripción de datos, estará formado por datos de una característica cualitativa, nombre, y otra cuantitativa, radio, de los satélites menores de Urano, es decir, aquellos que tienen un radio menor de 50 Km, dichos datos, los primeros cualitativos nominales, y los segundos cuantitativos continuos, son: (Nombre, radio en Km): Cordelia, 13; Ofelia, 16; Bianca, 22; Crésida, 33; Desdémona, 29; Julieta, 42; Rosalinda, 27; Belinda, 34; Luna-1986U10, 20; Calíbano, 30; Luna-999U1, 20; Luna 1999U2, 15.}''\\
			
			Para comenzar con la resolución de este ejercicio, deberemos escribir los datos en un fichero \texttt{.txt}, cumpliendo las siguientes normas: 
			
			\begin{itemize}
				\item Existirá una tabulación entre dato y dato. 
				\item La primera columna numera las filas, y en la primera fila se introduce un espacio y el nombre de las variables. 
				\item Se introducirá un salto de línea en la última fila
				\item Para los números decimales se utilizarán puntos. 
				\item Al escribir nombres, no se deberán introducir espacios. 
			\end{itemize}
			
			Obedeciendo a estas normas, copiamos los datos en un fichero llamado \texttt{satelites.txt}, y lo cargamos en R de la siguiente manera: 
			
			<<>>=
			s <- read.table("data/satelites.txt")
			print(s)
			@
			
			Ahora en la variable \texttt{s} tenemos un dataframe con los datos de nuestros satélites. En los dataframes se accede por \texttt{[fila, columna]}, y también podemos consultar las dimensiones con la función \texttt{dim}. Sería de esperar que nos dijera que tiene 12 filas (los 12 datos), y 2 columnas (\texttt{nombre} y \texttt{radio}). 
			
			<<>>=
			dim(s)
			@
			
			También podemos ordenar el dataframe, en función de una de las magnitudes (columnas), usando la función \texttt{order} aplicando recursivamente el concepto de acceder por filas y columnas. Veamos un ejemplo, si en \texttt{s} teníamos guardado nuestro dataframe, y queremos ordenar por \texttt{radio}, la manera de hacerlo sería la siguiente: 
			
			<<>>=
			s_ordered <- s[order(s$radio), ]
			print(s_ordered)
			@
			
			Podemos introducir nuevos criterios a la ordenación, como por ejemplo, hacerlo en orden descendente. Para esto usaremos la función \texttt{rev}. 
			
			<<>>=
			s_ordered_rev <- s[rev(order(s$radio)), ]
			print(s_ordered_rev)
			@
			
			También suele ser útil conocer cuántos elementos tiene una columna. Podemos averiguarlo con la función \texttt{length}, veamos un ejemplo. 
			
			<<>>=
			length(s$radio)
			@
			
			Otro valor que nos podemos plantear calcular es el rango. Para ello podemos usar las funciones \texttt{max} y \texttt{min}. Debemos tener cuidado con la función \texttt{range} y no confundirnos, pues nos dará los valores máximo y mínimo. 
			
			<<>>=
			r <- max(s$radio) - min(s$radio)
			print(r)
			range(s$radio)
			@
			
			Para una mejor lectura, podemos cambiar la forma de obtener la columna de los radios: 
			
			<<>>=
			radio <- s$radio
			@
			
			La idea de calcular la diferencia de el máximo y el mínimo a mano parece funcionar, sin embargo, para futuros casos sería más ágil tener codificada una función como la siguiente. 
			
			<<>>=
			rango <- function(radio){max(radio) - min(radio)}
			rango(radio)
			@
			
			Sin embargo, al salir de R, la definición de la función se pierde, por lo que deberemos guardarla en un fichero, y posteriormente cargarlo en futuras ejecuciones. Lo haremos de la siguiente manera: 
			
			<<>>=
			dump("rango", file = "fn/rango.R")
			source("fn/rango.R")
			@
			
			Volviendo al estudio de nuestros datos, veamos cómo calcular las diferentes frecuencias. Como en R no existe una función para las frecuencias relativas, se definirá y guardará una propia. 
			
			{\small
			<<>>=
			fabs_radio <- table(radio)
			fabsacum_radio <- cumsum(fabs_radio)
			frecrel <- function(r){table(r)/length(r)}
			dump("frecrel", file = "fn/frecrel.R")
			
			print(fabs_radio)
			print(fabsacum_radio)
			print(frecrel(radio))
			@
			}
			
			Otro valor que podemos calcular es la media aritmética de los datos, para ello se cuenta con la función \texttt{mean}. 
			
			<<>>=
			mr <- mean(radio)
			print(mr)
			@
			
			Ahora calcularemos la desviación típica, para ello se cuenta con la función \texttt{sd}. 
			
			<<>>=
			sdr <- sd(radio)
			print(sdr)
			@
			
			Sin embargo, el resultado obtenido no es el esperado. Esto se debe a que esta función realiza el siguiente cálculo
			$$
			\sigma = \sqrt{\frac{\displaystyle\sum_{i=0}^n (x_i-\bar{x})^2}{n-1}}
			$$
			que es más utilizado en inferencia estadística, porque hace que se parezca más a una campana de Gauss (menos sesgo), mientras que la fórmula vista en clase utiliza un factor de $n$ en vez de $n-1$ en el denominador (dentro de la raíz). Para ello, el profesor lo corrigió de la siguiente manera: 
			
			<<>>=
			sdr2 <- sqrt((sdr^2)*(length(radio)-1)/length(radio))
			print(sdr2)
			@
			
			En realidad lo que se está realizando es el siguiente ``ajuste'': 
			$$
			\sigma' = \sqrt{\sigma^2\cdot\frac{n-1}{n}}
			$$
			
			Una vez hemos visto cómo se calcula la desviación típica, podremos ver cómo calcular la varianza. Como sabemos que es el cuadrado de la desviación típica, bastaría con elevar al cuadrado si no fuera por el ``fallo'' de $n-1$ visto previamente. En este caso, el profesor lo arregló para el caso particular de la siguiente manera: 
			
			<<>>=
			varr <- var(radio)
			varr <- 11/12 * varr
			print(varr)
			@
			
			Otro de los valores que se ha enseñado cómo calcular, es la mediana. Para este caso existe la función \texttt{median}. 
			
			<<>>=
			medianr <- median(radio)
			print(medianr)
			@
			
			En último lugar, el profesor enseñó cómo calcular cuantiles, y para ello mostró la función \texttt{quantile}, pero se mencionó que se obtienen resultados diferentes a los esperados debido a la forma que tiene de calcularlos, y se deberá programar. Aquí se muestra un ejemplo de cómo se calcularía el primer cuartil. 
			
			<<>>=
			cuar1 <- quantile(radio, 0.25)
			print(cuar1)
			@
			
			Como añadido, el profesor explicó cómo abrir un ejemplo de Sweave, cómo pasarlo a un fichero que \LaTeX{} pudiese leer, y cómo compilarlo a PDF. Las instrucciones son las que se verán a continuación, aunque como ya se explicó en la introducción, usaremos otra forma de trabajar con estos archivos a lo largo de la práctica. 
			
			\begin{verbatim}
				rnwfile<-system.file("Sweave", "example-1.Rnw", package="utils")
				Sweave(rnwfile)
				tools::texi2pdf("example-1.tex")
			\end{verbatim}
		
		\section{Asociación}
		
			``\textit{El segundo conjunto de datos, que se empleará para realizar el análisis de asociación, estará formado por las siguientes 6 cestas de la compra: \{Pan, Agua, Leche, Naranjas\}, \{Pan, Agua, Café, Leche\}, \{Pan, Agua, Leche\}, \{Pan, Café, Leche\}, \{Pan, Agua\}, \{Leche\}.}''\\
				
			Lo primero explicado por el profesor fue la preparación de los datos proporcionados para que \texttt{arules} fuese capaz de tratar con ellos. Para ello se introduce una matriz de ceros y unos mediante el paquete \texttt{Matrix}, que indique en cada suceso, qué elementos contiene. La matriz es la siguiente:
			$$
			\begin{pmatrix}
				1 & 1 & 0 & 1 & 1\\
				1 & 1 & 1 & 1 & 0\\
				1 & 1 & 0 & 1 & 0\\
				1 & 0 & 1 & 1 & 0\\
				1 & 1 & 0 & 0 & 0\\
				0 & 0 & 0 & 1 & 0
			\end{pmatrix}
			$$
			
			Además, deberemos indicar las dimensiones de esta matriz $(6\times5)$, que estamos introduciendo los datos por filas (\texttt{byrow=TRUE}), y con \texttt{dimnames} ponemos los nombres a las filas y las columnas. El código es el siguiente. 
			
			<<>>=
			muestra <- Matrix(c(1, 1, 0, 1, 1,  
			1, 1, 1, 1, 0,  
			1, 1, 0, 1, 0,  
			1, 0, 1, 1, 0,  
			1, 1, 0, 0, 0,  
			0, 0, 0, 1, 0), 6, 5, byrow = TRUE, dimnames = list(
			c("suceso1", "suceso2", "suceso3", "suceso4", "suceso5", "suceso6"), 
			c("Pan", "Agua", "Café", "Leche", "Naranjas")), sparse=TRUE)
			muestra
			@
			
			A continuación, se ha enseñado cómo mostrar la matriz con puntos y barras, en vez de con unos y ceros. Se consigue con la función \texttt{as} y el parámetro \texttt{nsparseMatrix}. 
			
			<<>>=
			muestrangCMatrix <- as(muestra, "nsparseMatrix")
			muestrangCMatrix
			@
			
			Sin embargo, para el algoritmo debemos pasarle justo la transpuesta de la matriz con la que trabajamos, por ello se utiliza la función \texttt{t}. 
			
			<<>>=
			transpmuestrangCMatrix <- t(muestrangCMatrix)
			transpmuestrangCMatrix
			@
			
			Podemos consultar algunos datos acerca de los datos de nuestra matriz podemos usar la función \texttt{as} con el parámetro \texttt{transactions}. Además, con \texttt{summary} podemos ver un resumen de algunos parámetros básicos de los datos que contiene la matriz. 
			
			<<>>=
			transacciones = as(transpmuestrangCMatrix, "transactions")
			transacciones
			summary(transacciones)
			@
			
			Finalmente, podemos ejecutar el algoritmo apriori llamando a la función \texttt{apriori} del paquete \texttt{arules}. Definimos el soporte con un valor del 50\%, y la confianza con 80\%. 
			
			<<>>=
			asociaciones = apriori(transacciones, parameter = 
			list(support = 0.5, confidence = 0.8))
			@
			
			Podemos ver el resultado del algoritmo con la función \texttt{inspect}. 
			
			<<>>=
			inspect(asociaciones)
			@
			
			Aquí observamos el resultado del algoritmo. Debemos ignorar las dos primeras filas, pues no tiene sentido alguno que $\varnothing \rightarrow$ \{Leche\}, o que $\varnothing \rightarrow$ \{Pan\}, aparecen por cómo el autor del paquete codificó el algoritmo. En el resto de casos $A \rightarrow B$, nos indica cómo de probable es comprar $B$ cuando se compra $A$ (en función del soporte y la confianza provistas). 
			
			
		\section{Detección de datos anómalos}
			
			\subsection{Primer ejercicio}
			
				``\textit{El tercer conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas con base estadística, estará formado por los siguientes 7 valores de resistencia y densidad para diferentes tipos de hormigón \{Resistencia, Densidad\}: \{3, 2; 3.5, 12; 4.7, 4.1; 5.2, 4.9; 7.1, 6.1; 6.2, 5.2; 14, 5.3\}. Aplicar las medidas de ordenación a la resistencia y las de dispersión a la densidad.}''\\
				
				\begin{itemize}
					
					\item \textbf{Caja y Bigotes}
				
					Es una herramienta gráfica utilizada en estadística para representar la distribución de un conjunto de datos y detectar sucesos anómalos o outliers.
					
					Para realizar el cálculo de los outliers en clase, se introdujeron los datos en una matriz mediante \texttt{matrix}, luego se transpuso y se paso a un \texttt{dataframe}. Para esta primera técnica vamos a usar la primera columna (\textit{resistencia}).
					
					<<>>=
					muestra=t(matrix(c(3,2,3.5,12,4.7,4.1,5.2,4.9,7.1,6.1,6.2,5.2,14,5.3),
						2,7,dimnames=list(c("resistencia","densidad"))))
					
					(muestra=data.frame(muestra))
					@
					
					Una forma de obtener los outliers es mediante la función \texttt{boxplot}, pasándole la columna de los datos, el grado de outlier (\texttt{range}) o distancia a la que el suceso se considera outlier, y por último \texttt{plot=FALSE}, que se usa para no mostrar el gráfico como tal y solo sacar la información por el terminal.
					
					<<>>=
					(boxplot(muestra$r, range=1.5, plot=FALSE))
					@
					
					Como podemos ver en \texttt{\$out}, saca que el suceso outlier es el 14, lo cual como vimos en el ejercicio de la clase de teoría es correcto, pero, si nos fijamos en \texttt{\$conf}, podemos ver los límites del intervalo, pero estos no coinciden con los que vimos en clase, esto se debe a que, al igual que ocurría al usar la función \texttt{sd} para el cálculo de la desviación, R hace una distribución, ajustándola con unos porcentajes de probabilidad. Por lo que no son los valores exactos.
					
					Ahora vamos a hacerlo mediante el cálculo de los cuartiles como vimos en los ejercicios anteriores. Además, hemos calculado los límites del intervalo mediante la siguiente ecuación.
					
					$$
					(Q_1 - d \cdot (Q_3 - Q_1),\;Q_3 + d \cdot (Q_3 - Q_1))
					$$
					
					<<>>=
					(cuar1r=quantile(muestra$r, 0.25))
					
					(cuar3r=quantile(muestra$r, 0.75))
					
					(int=c(cuar1r-1.5*(cuar3r-cuar1r), cuar3r+1.5*(cuar3r-cuar1r)))
					@
					
					Por último, iteramos los elementos de la muestra y comprobamos para cada uno si es menor que el límite inferior del intervalo o si es mayor que el límite superior.
					
					<<>>=
					for (i in 1:length(muestra$r)) {
						if (muestra$r[i] < int[1] || muestra$r[i] > int[2]) {
							print("el suceso")
							print(i)
							print("es un suceso anómalo o outlier")
						}
					}
					@
					
					En este ejercicio, al igual que vimos en clase, el suceso outlier es el que está en la posición número 7, es decir el elemento 14.\\
					
					\item \textbf{Media y Desviación}
					
					Otra manera de buscar sucesos outliers usando técnicas con base estadística es mediante el uso de la media y la desviación típica. Aquí vamos a usar la otra columna del dataframe (\textit{densidad}), mediante el uso de las funciones \texttt{mean} y \texttt{sd} sacamos ambos valores, que unimos en los límites del intervalo mediante la siguiente ecuación.
					
					$$
					\bar{X_a} - d \cdot S_a,\;\bar{X_a} + d \cdot S_a
					$$
					
					<<>>=
					(media = mean(muestra$d))
					
					(desv = sd(muestra$d))
					
					(int=c(media-2*desv, media+2*desv))
					@
					
					Podemos ver que los valores inferior y superior del intervalo no son iguales que en el ejercicio que calculamos en clase, esto se debe a que, como ya vimos, la desviación típica se calcula mediante una distribución probabilistica, por lo que arreglando el cálculo de la desviación quedaría así.
					
					<<>>=
					(desv = sqrt(sd(muestra$d)^2 *
						(length(muestra$d)-1) / length(muestra$d)))
					
					(int=c(media-2*desv, media+2*desv))
					
					for (i in 1:length(muestra$d)) {
						if (muestra$d[i] < int[1] || muestra$d[i] > int[2]) {
							print("el suceso")
							print(i)
							print("es un suceso anómalo o outlier")
						}
					}
					@
					
					Como resultado, obtenemos los valores del intervalo correctos y podemos ver que el suceso anómalo es el que se encuentra en la posición 2, es decir el elemento 12.
					
				\end{itemize}
				
			\subsection{Segundo ejercicio}
			
				``\textit{El cuarto conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas basadas en la proximidad y en la densidad, estará formado por las siguientes 5 calificaciones de estudiantes: 1. \{4, 4\}; 2. \{4, 3\}; 3. \{5, 5\}; 4. \{1, 1\}; 5. \{5, 4\} donde las características de las calificaciones son: (Teoría, Laboratorio).}''
				
				\begin{itemize}
					
					\item \textbf{K-Vecinos}
					
					El algoritmo k-vecinos para identificar outliers basado en distancias consiste en calcular la distancia de un punto a sus k vecinos más cercanos y considerar los puntos con distancias mayores a un cierto valor (grado de outlier) como anómalos.
					
					En clase añadimos todos los datos de la nueva muestra a una matriz, que luego transpusimos para tener los datos dispuestos como nos requería el cálculo de distancias. Calculamos las distancias \textit{euclídeas} mediante la función \texttt{dist} y lo guardamos en una matriz de $5 \times 5$, para poder visualizar la distancia de cada punto hacia el resto. El cálculo de esta distancia se realiza de la siguiente manera.
					
					$$
					d(A, B) = \sqrt{(X_B - X_A)^2 + (Y_B - Y_A)^2}
					$$
				
					<<>>=
					muestra=matrix(c(4,4,4,3,5,5,1,1,5,4),2,5)
					
					muestra=t(muestra)
	
					distancias=as.matrix(dist(muestra))
					
					(distancias=matrix(distancias,5,5))
					@
					
					Mediante el siguiente bucle, iteramos cada punto y ordenamos de menor a mayor las distancias hacia los demás puntos.
					
					<<>>=
					for (i in 1:5) {
						distancias[,i] = sort(distancias[,i])
					}
					
					(distanciasordenadas=distancias)
					@
					
					Y por último, iteramos cada punto de la matriz de distancias ordenadas y comprobamos si el elemento k-éismo está a una distancia mayor de 2.5 (elegido arbitrariamente), donde el punto se consideraría outlier.
					
					En el código se puede ver que se elige el elemento 4 en vez del 3 que era la \texttt{K} elegida para resolverlo, esto se debe a que la primera fila de valores, son las distancias desde cada punto hacia sí mismo, es decir, siempre 0, por lo que los descartamos en el conteo de los \texttt{K} elementos.
					
					<<>>=
					for (i in 1:5) {
						if (distanciasordenadas[4,i] > 2.5) {
							print(i)
							print("es un suceso anómalo o outlier")
						}
					}
					@
					
					Podemos ver que como salida obtenemos que el punto 4 es un suceso anómalo o outlier, al igual que ocurría en el ejercicio resuelto en teoría.\\
					
					\item \textbf{LOF (Local Outlier Factor)}
					
					Como último ejercicio realizado en clase, se ha empleado el algoritmo LOF para identificar outliers basado en distancias, que evalúa la densidad local de puntos en relación con sus vecinos, identificando valores anómalos en regiones menos densas que el entorno circundante.
					
					Obtenemos una matriz de distancias haciendo uso igual que antes de la función \texttt{dist}, pero en este caso pasándole como parámetro el método que queremos que use para calcular la distancia (\texttt{method="manhattan"}), en este caso el método \textit{Manhattan}, que se calcula de la siguiente manera.
					
					$$
					d(A, B) = |X_B - X_A| + |Y_B - Y_A|
					$$
					
					<<>>=
					(distanciasM=as.matrix(dist(muestra, method="manhattan")))
					@
					
					Para finalizar, el profesor nombró algunos paquetes que realizaban una implementación no simplificada del algoritmo, estos son \texttt{RLof}, \texttt{DDoutlier} y \texttt{DMwR}, pero nosostros en el segundo ejercicio autónomo de detección de datos anómalos, sí vamos a implementar un código propio, que realice las simplificaciones oportunas.
				
				\end{itemize}
	
	\chapter{Ejercicios autónomos}
	
		\section{Descripción de los datos}
		
			``\textit{El primer conjunto de datos, que se empleará para realizar el análisis de descripción de datos, estará formado por datos de una característica cuantitativa, distancia, desde el domicilio de cada estudiantes hasta la Universidad, dichos datos, cuantitativos continuos, son: 16.5, 34.8, 20.7, 6.2, 4.4, 3.4, 24, 24, 32, 30, 33, 27, 15, 9.4, 2.1, 34, 24, 12, 4.4, 28, 31.4, 21.6, 3.1, 4.5, 5.1, 4, 3.2, 25, 4.5, 20, 34, 12, 12, 12, 12, 5, 19, 30, 5.5, 38, 25, 3.7, 9, 30, 13, 30, 30, 26, 30, 30, 1, 26, 22, 10, 9.7, 11, 24.1, 33, 17.2, 27, 24, 27, 21, 28, 30, 4, 46, 29, 3.7, 2.7, 8.1, 19, 16.}''\\
			
			Para empezar, hemos introducido todos estos datos en un fichero CSV. Para realizar este fichero se ha abierto un Excel y hemos ido introduciendo los datos en la primera columna. Cabe destacar que la primera fila no corresponde a ningún valor ya que hemos puesto \texttt{Distancia(km)} para mantener la estructura con respecto al ejercicio guiado. Una vez hemos introducido todos los datos guardamos el fichero con extensión \texttt{.csv}. Para leer este fichero dentro de R hacemos uso de la función \texttt{read.csv}, perteneciente al paquete por defecto \texttt{utils}. Esta función en realidad es un uso diferente de la función \texttt{read.table} orientado a la lectura de ficheros CSV. Esta función lee el archivo en formato tabla y a partir de él crea un data frame haciendo corresponder las filas y las columnas de la tabla. La función que hemos utilizado es \texttt{read.csv} primeramente porque es un fichero CSV y además porque está delimitado por comas (en caso de haber estado delimitado por punto y coma habría que haber usado \texttt{read.csv2}. Observamos en la siguiente línea de código cómo hemos creado un archivo \texttt{distancia\_universitarios.csv} siguiendo la estructura que hemos mencionado previamente. Con este fichero creado basta con llamar a la función \texttt{read.csv} pasando como parámetro el fichero. Si el archivo estuviera en otro directorio habría que pasar por parámetro la ruta donde se encuentra el archivo.
			
			<<>>=
			fichero = read.csv("data/distancia_universitarios.csv")
			fichero
			@
			
			Como podemos observar se nos ha leído correctamente el fichero, creando el dataframe con los datos correctamente leídos. Al ser un CSV delimitado por comas, hay que tener cuidado con los números decimales y separar estos por un punto, ya que si lo separamos por comas se nos leerán dos datos en vez de uno.\\ 
			
			Como vamos a trabajar todo el rato con la columna \texttt{Distancia} del dataframe, para no tener que estar accediendo todo el rato a esta podemos definirla en una variable nueva a la que llamaremos distancias, de tal forma que no tengamos que estar haciendo \texttt{fichero\$Distancia} todo el rato.
			
			<<>>=
			distancias = fichero$Distancia
			@
			
			Para saber la longitud de \texttt{distancias} hemos decidido elaborar nuestra propia función la cual nos dará un escalar con el número de elementos que haya en nuestra lista (distancias en este caso). 
			
			<<>>=
			len = function(list){
				count = 0
				for (element in list){
					count = count + 1
				}
				count
			}
			@
			
			Nuestra función len se basa en un contador el cual se inicializa a 0 y, por medio de un bucle, iterar todos los elementos de la lista y aumentar en 1 cada vez que haya un nuevo elemento. Por último, se devolverá el contador. Esta función será fundamental en otras funciones tal y como veremos más adelante. Vamos a ver cuántas distancias tenemos:
			
			<<>>=
			longitud = len(distancias)
			longitud
			@
			
			Observamos que tenemos 73 elementos, es decir, 73 distancias. La próxima utilidad que necesitamos es la ordenación de nuestra lista de distancias. Para ello hemos elaborado una función que ordenará la lista en sentido ascendente o descendente utilizando para ello el método de la burbuja. \\
			
			El método de la burbuja consiste en ir evaluando por pares todos los elementos de una lista, de tal forma que se vayan reposicionando según el sentido en el que se esté ordenando. En caso de ir ordenando en sentido ascendente, el mayor elemento de la lista se irá reposicionando hasta llegar a la derecha del todo. En caso de hacerlo en sentido descendente, el elemento que quedará a la derecha del todo será el menor. Conforme se vaya avanzando, tendremos por cada iteración un elemento más colocado a la derecha del todo, y así sucesivamente hasta que todos los elementos queden ordenados. La función que realiza este método de ordenación es la siguiente:
			
			<<>>=
			bubble = function(list, asc = TRUE){
				n = len(list)
				if(asc){
					for (i in 2:n){
						for (j in 1:(n-1)){
							if (list[j] > list[j+1]){
								temp = list[j]
								list[j] = list[j+1]
								list[j+1] = temp
							}
						}
					}
				}
				else {
					for (i in 2:n){
						for (j in 1:(n-1)){
							if (list[j] < list[j+1]){
								temp = list[j]
								list[j] = list[j+1]
								list[j+1] = temp
							}
						}
					}
				}
				list
			}
			@
			
			A esta función habrá que pasarle la lista que se quiere ordenar y \texttt{TRUE} o \texttt{FALSE} para indicar en el sentido que se quiere ordenar. En caso de ser \texttt{TRUE} se ordenará ascendentemente, y en caso de \texttt{FALSE} se ordenará descendentemente. Por defecto, si solo se pasa como parámetro la lista, se ordenará de forma ascendente. Vamos a hacer la prueba con nuestra lista de distancias:
			
			{\small 
			<<>>=
			distancias_asc = bubble(distancias)
			distancias_asc
			
			distancias_desc = bubble(distancias, FALSE)
			distancias_desc
			@
			}
			
			Con la lista ordenada se puede saber de forma muy sencilla el rango. Previamente, en los ejercicios guiados, teníamos que llamar a las funciones \texttt{max} y \texttt{min}. Con la lista ordenada, se pueden acceder a estos valores, ya que estarán en el primer y último índice en función del sentido en el que hayamos ordenado la lista. Es por ello que nos resulta muy fácil crear una función rango.
			
			<<>>=
			rank = function(list){
				ordered_list = bubble(list)
				ordered_list[len(ordered_list)] - ordered_list[1]
			}
			@
			
			Primeramente hemos ordenado la lista en orden ascendente, de tal forma que el valor máximo se encontrará en el último índice y el valor mínimo en el primero. Lo que hacemos para calcular el rango es restar el elemento del último índice menos el del primero. Comprobamos nuestra función y observamos que nos sale un rango de 45.
			
			<<>>=
			rango_dist = rank(distancias)
			rango_dist
			@
			
			Ahora vamos a realizar el cálculo de las frecuencias absoluta y relativa y sus respectivas acumuladas. Para ello, nuevamente crearemos una función para cada una. La primera que vamos a realizar y en la que se van a basar el resto será la frecuencia absoluta. El código de la función es el siguiente:
			
			<<>>=
			absolute_freq = function(list){
				ordered_list = bubble(list)
				n = len(ordered_list)
				elements = vector()
				frequencies = vector()
				i = 1
				while (i <= n){
					actual_element = ordered_list[i]
					elements = append(elements, actual_element)
					actual_freq = 0
					j = i
					while(j <= n & actual_element == ordered_list[j]){
						actual_freq = actual_freq + 1
						j = j+1
					}
					frequencies = append(frequencies, actual_freq)
					i = j
				}
				rbind(elements, frequencies)
			}
			@
			
			El algoritmo consiste en iterar toda la lista. Tenemos dos listas auxiliares, una de elementos y otra de las frecuencias de esos elementos. Con la lista ordenada, cada vez que encontremos un elemento distinto del anterior, lo apuntaremos en la lista de elementos, y mientras continuamos iterando la lista vamos apuntando en un contador auxiliar las veces que va apareciendo es elemento. Nótese que el elemento va a aparecer contiguo y no va a volver a aparecer en l resto de la lista ya que previamente la hemos ordenado. De esta forma, encontramos un elemento, contamos las veces contiguas que aparece y cuando aparece otro elemento apuntamos las frecuencias del anteior e inciamos el mismo procedimiento con el siguiente elemento. Una vez completamos la iteración de la lista devolvemos con rbind una matriz que contiene ambas listas de elementos y sus correspondientes frecuencias.\\
			
			Para esta función hemos utilizado las funciones de append (paquete base) que devuelve un vector con la lista que se pasa como parámetro y el elemento que se introduce como parámetro concatenado a la derecha del mismo, y la función rbind (paquete base), que devuelva una matriz con los vectores que se pasan como parámetros a modo de fila. Comprobamos las frecuencias absolutas:
			
			{\small
			<<>>=
			frecuencia_abs = absolute_freq(distancias)
			frecuencia_abs
			@
			}
			
			Una vez hemos hecho las frecuencias absolutas pasamos a hacer las frecuencias relativas. La frecuencia relativa no es más que la frecuencia absoluta de un elemento dividido entre el total de elementos. Para realizar este cálculo disponemos de todas las herramientas, ya que tenemos la función \texttt{len} que nos dice cuántos elementos hay y la función de frecuencias absolutas que hemos visto ahora mismo. Podemos codificar otra función que devuelva una matriz (con \texttt{rbind} al igual que hemos visto en el ejercicio anterior) con los elementos distintos de la lista y su frecuencia absoluta dividida entre la longitud de la misma. Siguiendo esta idea, el código de la función es el siguiente.
			
			<<>>=
			relative_freq = function(list){
				f_abs = absolute_freq(list)
				elements = f_abs[1,]
				abs_fvalues = f_abs[2,]
				rbind(elements,abs_fvalues/len(list))
			}
			@
			
			Y comprobamos las frecuencias relativas de la lista.
			
			{\small
			<<>>=
			frecuencia_rel = relative_freq(distancias)
			frecuencia_rel
			@
			}
			
			Por último, vamos a elaborar dos funciones para las frecuencias acumuladas absoluta y relativa. Con todas las frecuencias de cada elemento y la lista ordenada podemos iterar la lista de frecuencias e ir sumando para cada elemento la suma de las frecuencias de los elementos menores o iguales al elemento del que se está calculando. Dependiendo de qué frecuencia acumulada se esté calculando tendremos que trabajar con la función de frecuencias absolutas (\texttt{absolute\_freq}) o con la de frecuencias relativas (\texttt{relative\_freq}). Iremos iterando cada elemento e iremos creando un nuevo vector con la frecuencia acumulada. Los códigos de las funciones que realizan la frecuencia absoluta acuulada y la frecuencia relativa acumulada son respectivamente los siguientes:
			
			<<>>=
			acum_absolute_freq = function(list){
				f_abs = absolute_freq(list)
				elements = f_abs[1,]
				abs_fvalues = f_abs[2,]
				acum_abs_fvalues = vector()
				acum = 0
				for (i in 1:len(elements)){
					acum = acum + abs_fvalues[i]
					acum_abs_fvalues = append(acum_abs_fvalues, acum)
				}
				rbind(elements, acum_abs_fvalues)
			}
			@
			
			<<>>=
			acum_relative_freq = function(list){
				f_rel = relative_freq(list)
				elements = f_rel[1,]
				rel_fvalues = f_rel[2,]
				acum_rel_fvalues = vector()
				acum = 0
				for (i in 1:len(elements)){
					acum = acum + rel_fvalues[i]
					acum_rel_fvalues = append(acum_rel_fvalues, acum)
				}
				rbind(elements, acum_rel_fvalues)
			}
			@ 
			
			Como se puede observar es el mismo código solo que en uno trabajamos con las frecuencias absolutas y en el otro con las relativas. Comprobamos su funcionamiento:
			
			{\small
			<<>>=
			frecuencia_abs_acum = acum_absolute_freq(distancias)
			frecuencia_abs_acum
			
			frecuencia_rel_acum = acum_relative_freq(distancias)
			frecuencia_rel_acum
			@
			}
			
			Se puede comprobar que están bien ya que la frecuencia absoluta acumulada del último elemento es igual al número total de elementos (73) y la frecuencia relativa acumulada del último elemento es 1.\\
			
			Prosiguiendo con el análisis de datos, tenemos que obtener la moda del conjunto de datos. Para ello hemos elaborado una función que nos calculará este valor. Ayudándonos de las frecuencias absolutas, podemos iterar estas y buscar la mayor frecuencia, cuyo elemento asociado será la moda. Así vamos iterando la frecuencia de cada elemento diferente de la lista y vamos comprobando si su frecuencia es la mayor hasta ahora. En caso de serlo, la moda temporal correspondera a ese elemento. Así observaremos todos los elementos, devolviendo después de terminar la iteración de la lista el elemento con mayor frecuencia, la moda. El código que incluye esta funcionalidad es el siguiente:
			
			{\small
			<<>>=
			mode = function(list){
				frequencies = absolute_freq(list)
				elements = frequencies[1,]
				freq_values = frequencies[2,]
				actual_mode = 0
				actual_mode_val = 0
				for (i in 1:len(elements)){
					if (freq_values[i] > actual_mode_val){
						actual_mode_val = freq_values[i]
						actual_mode = elements[i]
					}
				}
				actual_mode
			}
			@
			}
			
			Y extraemos la moda de nuestro conjunto de datos:
			
			<<>>=
			moda = mode(distancias)
			moda
			@
		
			Observamos que la moda del conjunto de distancias es 30. Podemos comprobar que está bien si nos fijamos en las frecuencias absolutas, ya que el elemento más que tiene es el 30 con una frecuencia absoluta de 8. Cabe destacar que en caso de haber dos o más elementos con la misma mayor frecuencia del conjunto de datos el algoritmo devolverá el elemento de menor magnitud al iterar el algoritmo de menor a mayor elemento.\\
			
			El siguiente análisis que tendremos que hacer es el de la mediana, que ya hemos visto que es el dato que divide en dos al conjunto total de datos. Para calcular este valor tendremos que fijarnos en la paridad del número total de datos. Y es que si este es par o impar se calculará de una forma u otra. Para saber si un número es par o impar bastará con ver su módulo 2 (valor del resto del número dividido entre 2). Si este es 0 estamos ante un número par, en caso contrario ante uno impar.\\
			
			En caso de tener un número de elementos par tendremos que coger con la lista ordenada el elemento $\frac{n}{2}$ y el elemento $\frac{n}{2} + 1$, sumarlos y dividir entre dos. En caso de tener un número de elementos impar directamente tendremos que coger el elemento $\frac{n+1}{2}$.\\
			
			Hemos englobado estos cálculos en una función, donde comprobamos si estamos ante un número de elementos par o impar y accedemos a los elementos correspondientes. La función es la siguiente:
			
			<<>>=
			median_value = function(list){
				n = len(list)
				ordered_list = bubble(list)
				if (n%%2 == 0){
					median = (ordered_list[n/2] + ordered_list[(n/2)+1]) / 2
				}
				else{
					median = ordered_list[(n+1)/2]
				}
				median
			}
			@
			
			Comprobamos el valor de la mediana de nuestro conjunto de datos:
			
			<<>>=
			mediana = median(distancias)
			mediana
			@
			
			Vemos que el valor medio es 20. Estamos en lo correcto, ya que si nos fijamos en el conjunto ordenado de los datos vemos que tenemos 73 elementos (número impar), luego la mediana será el elemento $\frac{73+1}{2}$; es decir, el elemento 37 que vemos que es el 20, el valor que nos ha salido como mediana. \\
			
			Tras haber codificado las medidas de tendencia central, vamos a estudiar dos medidas de dispersión. La primera de las medidas que vamos a calcular es la desviación típica. Para ello hemos codificado la siguiente función:
			
			<<>>=
			standard_dev = function(list){
				mean = mean(list)
				n = len(list)
				add = 0
				for (i in 1:n){
					add = add + ((list[i] - mean)^2)
				}
				sqrt(add/n)
			}

			@
			
			Como se puede observar, la función consiste en ir sumando las diferencias entre cada dato y la media de todos ellos elevadas al cuadrado. El \texttt{for} de la función es el encargado de realizar esta tarea. Tras ello, se divide el resultado entre el número total de datos y se realiza la raíz cuadrada de la medida obtenida. La desviación típica, por tanto, obedece a la fórmula: \\
			
			$$
			\sigma = \sqrt{\frac{\displaystyle\sum_{i=0}^n (x_i-\bar{x})^2}{n}}
			$$
			
			La desviación típica de nuestro conjunto de datos será por tanto la siguiente:
			
			<<>>=
			desviacion = standard_dev(distancias)
			desviacion
			@
			
			La segunda y última medida de dispersión que vamos a estudiar es la varianza, que en el fondo, no es más que elevar la desviación típica al cuadrado.
			
			<<>>=
			variance = function(list){
				dev = standard_dev(list)
				var = dev^2
				var
			}
			@
			
			Con esta función, calculamos la varianza en el conjunto de datos:
			
			<<>>=
			varianza = variance(distancias)
			varianza
			@
			
			Terminadas las medidas de dispersión, vamos a proceder a calcular los cuantiles. Para calcular los cuantiles tendremos que definir además de la lista de la que queremos calcular el valor de c (que es ...). Esto último tendrá que corresponder a un valor entre 0 y 1 en función de c. Así, si introducimos por parámetro un c que no es válido se nos devolverá \texttt{NULL}, ya que no se puede hacer un cálculo. En caso de haber introducido un c válido tendremos que observar dos casos.
			
			\begin{itemize}
				\item Si $n c$ (siendo n el número total de elementos) es natural tendremos que coger los elementos $n c$ y $n c + 1$, los sumaremos y dividiremos entre 2.
				\item Si $n c$ (siendo n el número total de elementos) no es natural, se deberá coger el elemento $\left\lfloor nc \right\rfloor + 1$, siendo $\left\lfloor n c \right\rfloor$ la parte entera del producto.
			\end{itemize}
			
			Con estos cálculos podemos codificar una función que nos da los cuantiles. La función es la siguiente:
			
			<<>>=
			quant = function(list, c){
				ordered_list = bubble(list)
				n = len(list)
				if (c < 0 | c > 1){
					quant = NULL
				}
				else{
					if((n*c)%%1 == 0){
						quant = (ordered_list[(n*c)] +
						 ordered_list[(n*c) + 1]) / 2
					}
					else {
						int_prod = floor(n*c)
						quant = ordered_list[int_prod + 1]
					}
				}
				quant
			}	
			
			@
			
			Para poder comprobar si $n c \in \mathbb{N}$,  calculamos $nc \pmod{1}$. Cualquier número entero dividido entre 1 nos va a dar de resto 0; en caso contrario dará otra cosa que no sea 0. Además, aseguramos que el producto, en caso de ser entero, nos va a dar un número natural ya que siempre va a ser positivo. Esto es por dos razones fundamentales:
			
			\begin{itemize}
				\item Siempre se cumplirá que $n \geq 0$. 
				\item Siempre se cumplirá que $0 \leq c \leq 1$. 
			\end{itemize}
			
			En caso de estar ante un número que no es natural tendremos que acceder a la parte entera del producto. Para poder acceder a ella hemos hecho uso de la función \texttt{floor} perteneciente al paquete \texttt{base}. Esta función recoge como parámetro un número y devuelve su aproximación en número entero redondeado hacia abajo. Por ejemplo, si aplicamos esta función a $4.99$ nos devolverá 4, pues $\lfloor4.99\rfloor = 4$.\\
			
			Con esta función podremos calcular cuantiles, entre los que se incluyen cuartiles, deciles, percentiles... Para probar la función vamos a calcular los tres cuartiles $\frac{1}{4}, \frac{2}{4}$ y $\frac{3}{4}$.
			
			<<>>=
			cuartil1 = quant(distancias,0.25)
			cuartil2 = quant(distancias,0.5)
			cuartil3 = quant(distancias,0.75)
			cuartilerr = quant(distancias, -0.2)
			
			cuartil1
			cuartil2
			cuartil3
			cuartilerr
			@
			
			Observamos que los valores de los cuartiles 1, 2 y 3 son 8.1, 20 y 28. Además hemos probado a meter un valor de $c$ no válido y verificamos que efectivamente nos devuelve \texttt{NULL} ya que ese cálculo no sería lógicamente correcto. También comprobamos que el valor del segundo cuartil es igual al de la mediana que hemos calculado más arriba. Ambos valores deben coincidir ya que hacen referencia al mismo elemento que realiza la misma división de los datos.
			
		\section{Asociación}
		
			``\textit{El segundo conjunto de datos, que se empleará para realizar el análisis de asociación, estará formado por las siguientes conjuntos de extras incluidos en 8 ventas de coches: \{X, C, N, B\}, \{X, T, B, C\}, \{N, C, X\}, \{N, T, X, B\}, \{X, C, B\}, \{N\}, \{X, B, C\}, \{T, A\}. Donde: \{X: Faros de Xenon, A: Alarma, T: Techo Solar, N: Navegador, B: Bluetooth, C: Control de Velocidad\}, son los extras que se pueden incluir en cada coche.}''
			
			<<>>=
			union = function(c1, c2) {
				if (len(c1) == 0) {
					c2
				} else if (is.element(c1[1], c2)) {
					union(c1[-1], c2)
				} else {
					union(c1[-1], append(c2, c1[1]))
				}
			}
			
			intersect = function(c1, c2){
				if (len(c1) == 0) {
					c()
				} else if (is.element(c1[1], c2)) {
					append(intersect(c1[-1], c2), c1[1])
				} else {
					intersect(c1[-1], c2)
				}
			}
			
			dif = function(c1, c2) {
				res = c()
				for (element in c1) {
					if (!(element %in% c2)) {
						res = append(res, element)
					}
				}
				res
			}
			@
			
			
			
			<<>>=
			count_appearance = function(table, elements){
				count = 0
				for (i in 1:len(table[,1])){
					acum = 1
					for (element in elements){
						acum = (table[i,element]) & acum
					}
					count = count + acum
				}
				count
			}
			@
			
			
			
			<<>>=
			support = function(table, elements) {
				count_appearance(table, elements) / len(table[,1])
			}
			
			support_clasif = function(table, ocurrences, s){
				valid_ocurrences = c()
				for (ocurrence in ocurrences){
					support_oc = support(table, ocurrence)
					if (support_oc >= s){
						valid_ocurrences = append(valid_ocurrences, ocurrence)
					}
				}
				valid_ocurrences	
			}
			@
			
			
			
			<<>>=
			create_comb = function(table, clasif, s) {
				combinations = c()
				dim = 2
				next_dim = TRUE
				while (dim <= len(clasif) & next_dim == TRUE) {
					next_dim = FALSE
					comb = unlist(lapply(dim, function(m) {
						combn(clasif, m=m, simplify=TRUE)
						}), recursive=FALSE)
					
					for (j in seq(1, len(comb), by=dim)) {
						add = c()
						for (k in j:(j+dim-1)) {
							add = append(add, comb[k])
						}
						if (support(table, add) >= s) {
							next_dim = TRUE
							combinations = append(combinations, list(add))
						}
					}
					dim = dim+1
				}
				combinations
			}
			@
			
			
			
			<<>>=
			confidence = function(table, left, right) {
				count_appearance(table, union(left, right)) /
					count_appearance(table, left)
			}
			
			get_asotiations = function(table, comb, c) {
				kMax = len(comb[len(comb)][[1]])
				listLeft = list()
				listRight = list()
				
				for (i in 2:kMax) {
				
					split = Filter(function(x) length(x)==i, comb)
					
					for (j in 1:len(split)) {
					
						for (k in 1:(i-1)) {
						
							leftSides = lapply(k, function(m) {
								combn(split[j][[1]], m=m, simplify=TRUE)})
							
							df = do.call(rbind.data.frame, leftSides)
							
							for (n in 1:len(df[1,])) {
							
								all = split[j][[1]]
								
								left = df[,n]
								
								right = dif(split[j][[1]], df[,n])
								
								if (confidence(table, left, right) >= c) {
								
									listLeft = append(listLeft , list(left))
									listRight = append(listRight , list(right))
								
								}
							}
						}
					}
				}
				asoc = data.frame(left = I(listLeft), right = I(listRight))
				asoc
			}
			@
			
			
			
			<<>>=
			apriori = function(table, elements, s, c) {
				soporte_clasif = support_clasif(table, elements, s)
				
				combinations = create_comb(table, soporte_clasif, s)
				
				if (len(combinations) > 0) {
				
					conf = get_asotiations(table, combinations, c)
					print(conf)
				
				} else {
					print("No hay ninguna combinación que pase el soporte")
				}
			}
			@
			
			
			
			<<>>=
			elements = c(c("X"), c("A") ,c("T"), c("N"), c("B"), c("C"))
			
			tabla = matrix(c(
				1,0,0,1,1,1,
				1,0,1,0,1,1,
				1,0,0,1,0,1,
				1,0,1,1,1,0,
				1,0,0,0,1,1,
				0,0,0,1,0,0,
				1,0,0,0,1,1,
				0,1,1,0,0,0),8,6,byrow=TRUE,dimnames=list(
			c("occu1","occu2","occu3","occu4","occu5","occu6","occu7","occu8"),
			c("X", "A", "T", "N", "B", "C")))
			
			apriori(tabla, elements, 0.5, 0.8)
			@
			
			
		
		\section{Detección de datos anómalos}
		
			\subsection{Primer ejercicio}
			
				``\textit{El tercer conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas con base estadística, estará formado por los siguientes 10 valores de velocidades de respuesta y temperaturas normalizadas de un microprocesador \{Velocidad, Temperatura\}: \{10, 7.46; 8, 6.77; 13, 12.74; 9, 7.11; 11, 7.81; 14, 8.84; 6, 6.08; 4, 5.39; 12, 8.15; 7, 6.42; 5, 5.73\}. Aplicar las medidas de ordenación a la velocidad y las de dispersión a la temperatura.}''\\
				
				Como hemos visto previamente, el cálculo de \textit{outliers} por medio de técnicas con base estadística no proporciona los mismos resultados que nos salían en clase, ya que hay ciertos cálculos (como el de los cuartiles o la desviación) que están realizados de forma diferente a como hemos visto; y esto implica un error que se propaga al cálculo de los intervalos para valores atípicos y por consecuente al resultado final.  Si recordamos, en la sección 2.1 (correspondiente a los ejercicios autónomos de descripción de los datos) hemos hecho nuestras propias funciones que nos proporcionan los resultados correctos a los cálculos de todo lo que necesitamos. Es por ello que, en base a estas funciones, vamos a realizar los algoritmos correspondientes:\\
				
				En primer lugar vamos a introducir los datos. Para ello lo vamos a hacer tal y como hemos visto previamente, con la función \texttt{matrix}, de tal forma que esta tenga dos columnas (una para velocidad y otra para temperatura) y tantas filas como entradas de datos tenemos. Tras ello, pasamos esta matriz a un \texttt{dataframe} para operar sobre los datos de una forma más cómoda. El resultado es algo así:\\
				
				<<>>=
				muestra = t(matrix(c(10,7.46,8,6.77,13,12.74,9,7.11,11,7.81,14,8.84,6,
				6.08,4,5.39,12,8.15,7,6.42,5,5.73),
				2,11,dimnames=list(c("velocidad","temperatura"))))
				muestra=data.frame(muestra)
				
				muestra
				@
				
				Observamos que tenemos los datos dispuestos en dos columnas, una para \textit{velocidad} y otra para \textit{temperatura}. También tenemos 11 filas, que corresponde con el número total de parejas \textit(velocidad, temperatura) entrantes al conjunto de datos.\\
				
				\textbf{\large{Medidas de ordenación (caja y bigotes)}}\\
				
				Con los datos organizados podemos empezar a trabajar. Lo primero de todo será aplicar las medidas de ordenación a la velocidad. Esto quiere decir aplicar el algoritmo de caja y bigotes que hemos visto en la sección 1.3. Primeramente, vamos a centrar nuestra atención en la columna \textit{velocidad}, que es la que nos interesa:\\
				
				<<>>=
				muestra_velocidad = muestra$velocidad
				@
				
				Con esta línea de código guardamos la columna de velocidad, y podremos llamar a nuestra función que implementa el algoritmo directamente con \texttt{muestra\_velocidad}. Una vez tenemos todo listo vamos a ver el código de nuestro algoritmo.\\
				
				<<>>=
				boxNmustaches = function(sample, d, details = FALSE){
					outliers = c()
					if(details){
						print("->PASO 1: DETERMINACIÓN DEL GRADO DE OUTLIER")
						cat("Se ha introducido un grado de outlier d = ",d,"\n\n")
					}
					cuart1 = quant(sample, 0.25)
					cuart3 = quant(sample, 0.75)
					if (details){
						print("->PASO 2: CÁLCULO DE LOS CUARTILES 1 Y 3")
						cat("El cuartil 1 es ",cuart1, " y el cuartil 3 es ", cuart3,"\n\n")
					}
					lim_inf = cuart1 - (d*(cuart3-cuart1))
					lim_sup = cuart3 + (d*(cuart3-cuart1))
					if (details){
						print("->PASO 3: CÁLCULO DE LOS LÍMITES DEL INTERVALO PARA VALORES ATÍPICOS")
						cat("Fórmula -> (Q1 - d*(Q3-Q1), Q3 + d*(Q3-Q1))\n")
						cat("El intervalo para los valores atípicos es: (",lim_inf,", ",lim_sup,")\n\n")
					}
					if(details){
						print("->PASO 4: IDENTIFICACIÓN DE OUTLIERS")
						cat("Los outliers serán aquellos valores que no están en el intervalo anterior\n")
					}
					for (i in 1:len(sample)){
						if(sample[i] < lim_inf || sample[i] > lim_sup){
							outliers = append(outliers, i)
							if(details){
								cat("El punto ",i," con valor ",sample[i]," es un outlier\n")
							}
						}
					}
					if(len(outliers) == 0){
						cat("No hay outliers")
					}
				outliers
				}
				@
				
				Para empezar, nuestra función recibe los siguientes parámetros:\\
				
				\begin{itemize}
					\item \texttt{sample}: El data frame con los datos correspondientes. En nuestro caso sería \texttt{muestra\_velocidad}
					\item \texttt{d}: El grado de \textit{outlier} a partir del cual un dato se considera anómalo. Servirá para calcular el intervalo para valores atípicos.
					\item \texttt{details}: Es un parámetro que por defecto estará a \texttt{FALSE}, y que servirá para que el usuario indique si quiere una salida detallada o sencilla. Con salida sencilla nos referimos a una lista con los índices de los puntos que se han evaluado como \textit{outliers}, mientras que con salida detallada se devolverá esto mismo además de una serie de mensajes por pantalla donde se detalla cada paso y lo que se hace en él, así como los resultados parciales que vamos obteniendo.
				\end{itemize}
				
				Vamos a centrarnos en la salida detallada para ir explicando poco a poco el algoritmo.\\
				
				\begin{itemize}
					\item \texttt{Paso 1}: En este paso determinamos el grado de outlier el cual es elegido arbitrariamente por el usuario. Esta parte del algoritmo no es más que reescribir el parámetro \texttt{d} que ha introducido a la hora de llamar a la función. Además, hacemos uso de \texttt{cat}, función contenida en el paquete \texttt{base} y que permite realizar salidas por pantalla con argumentos. En nuestro caso, queremos imprimir por pantalla, además de un mensaje, el valor de \texttt{d} en la misma línea. Para evitar hacer dos \texttt{print}, usamos esta función que pasará el valor de \texttt{d} a la cadena de texto que se imprimirá.
					
					\item \texttt{Paso 2}: En este paso vamos a calcular los cuartiles 1 y 3 (0.25 y 0.75) para posteriormente utilizarlos en el cálculo del intervalo para valores atípicos. Observamos que hacemos uso de la función \texttt{quant} que habíamos definido en la sección 2.1. Además, si el usuario lo desea, se imprime por pantalla el valor de ambos.
					
					\item \texttt{Paso 3}: Una vez calculados los cuartiles vamos a calcular el intervalo que nos permitirá clasificar los \textit{outliers}. Para ello calculamos \texttt{lim\_inf} y \texttt{lim\_sup} que serán los límites inferior y superior respectivamente, ambos mediante la fórmula que hemos visto en la sección 1.3. El hecho de haber utilizado nuestra función \texttt{quant} para el cálculo de los cuartiles permite que el intervalo sea ahora el que nos salió en clase de teoría.
					
					\texttt{Paso 4}: Por último, recorremos todos los datos y buscamos aquellos que estén por debajo del límite inferior o por encima del límite superior, ya que al no estar comprendido en el intervalo se consideran datos anómalos. Además, añadimos a una lista \texttt{outliers} (previamente vacía) estas anomalías para posteriormente devolverlas.\\
				\end{itemize}
				
				Con este algoritmo vamos a resolver el ejercicio. Vamos a llamar a la función \texttt{boxNmustaches} con \texttt{muestra\_velocidad} y un valor $d = 1.5$.\\
				
				<<>>=
				anomalias_vel = boxNmustaches(muestra_velocidad, 1.5, TRUE)
				@
				
				Observamos cómo se informa al usuario del grado de \textit{outlier} que ha introducido, de los valores de los cuartiles 1 y 3, de cómo se calcula el intervalo para valores atípicos y de todos aquellos \textit{outliers} que se han encontrado. En este ejemplo concreto no hay \textit{outliers} ya que todos los valores se encuentran dentro del intervalo establecido. Si se quisiera acceder a la lista que contiene todos los \textit{outliers} bastaría con acceder en este ejemplo a \texttt{anomalias\_vel}.\\
				
				\textbf{\large{Medidas de dispersión}}\\
				
				En este segundo apartado del ejercicio vamos a detectar anomalías, esta vez sobre la columna de temperatura y aplicando medidas de dispersión. El cálculo del intervalo se realiza esta vez con la media aritmética y la desviación típica. Como hemos ido viendo, el cálculo de la desviación típica mediante la función \texttt{sd} es diferente que el que hemos visto en teoría. Por ello, podemos aplicar la función \texttt{standard\_dev} que hemos elaborado en la sección 1.3 y que nos da el valor que hemos visto en clase de teoría. Primeramente vamos a guardarnos la columna de temperaturas para luego trabajar mejor sobre ella.
				
				<<>>=
				muestra_temp = muestra$temperatura
				@
				
				Ya tenemos los datos de temperatura, así que solo queda llamar a la función que implementa este algoritmo. Es bastante similar a la función anterior de \texttt{boxNmustaches}, solo que ahora en vez de calcular cuartiles calculamos la media aritmética y la desviación típica; y la fórmula del intervalo para valores atípicos también cambia, tal y como hemos visto en la sección 1.3. La función que implementa el algoritmo es la siguiente:
				
				<<>>=
				dispersed_outliers = function(sample, d, details = FALSE){
					outliers = c()
					if(details){
						print("->PASO 1: DETERMINACIÓN DEL GRADO DE OUTLIER")
						cat("Se ha introducido un grado de outlier d = ",d,"\n\n")
					}
					mean_sample = mean(sample)
					if (details){
						print("->PASO 2: CÁLCULO DE LA MEDIA ARITMÉTICA")
						cat("La media aritmética es ", mean_sample, "\n\n")
					}
					dev_sample = standard_dev(sample)
					if (details){
						print("->PASO 3: CÁLCULO DE LA DESVIACIÓN TÍPICA")
						cat("La desviación típica es ", dev_sample, "\n\n")
					}
					lim_inf = mean_sample - (d*dev_sample)
					lim_sup = mean_sample + (d*dev_sample)
					if (details){
						print("->PASO 4: CÁLCULO DE LOS LÍMITES DEL INTERVALO PARA VALORES ATÍPICOS")
						cat("Fórmula -> (Media - d*DesviaciónTípica, Media + d*DesviaciónTípica)\n")
						cat("El intervalo para los valores atípicos es: (",lim_inf,", ",lim_sup,")\n\n")
					}
					if(details){
						print("->PASO 5: IDENTIFICACIÓN DE OUTLIERS")
						cat("Los outliers serán aquellos valores que no están en el intervalo anterior\n")
					}
					for (i in 1:len(sample)){
						if(sample[i] < lim_inf || sample[i] > lim_sup){
							outliers = append(outliers, i)
							if(details){
								cat("El punto ",i," con valor ",sample[i]," es un outlier\n")
							}
						}
					}
					if(len(outliers) == 0){
						cat("No hay outliers")
					}
					outliers
				}
				@
				
				Como podemos ver el código es prácticamente igual. Se pasan los mismos parámetros que en el algoritmo anterior. El primer paso recuerda al usuario el grado de dispersión que ha introducido y el segundo  y tercer paso calculan la media y la desviación típica con nuestras funciones que lo hacen como hemos visto en teoría. El cuarto paso calcula los límites del intervalo para valores atípicos haciendo uso de la media y la desviación típica previamente calculadas y con la fórmula que vimos en la sección 1.3, y finalmente se recorren todos los datos en busca de los valores que no están dentro del intervalo calculado.\\
				
				Al igual que en el algoritmo anterior, se devolverá una lista con los puntos que son \textit{outliers} y se podrá elegir entre una salida detallada con mensajes por pantalla del proceso o una salida limitada a la devolución de la lista de \textit{outliers}.\\
				
				Vamos a probar nuestro algoritmo con la temperatura y un grado de dispersión $d=2$:
				
				<<>>=
				anomalias_temp = dispersed_outliers(muestra_temp,2,TRUE)
				@
				
				Observamos cómo se ha ido haciendo todo el proceso (porque hemos puesto que queremos una salida detallada) y vemos que al final se ha encontrado una anomalía en el punto 3 cuyo valor es 12.74, el cual se encuentra fuera del intervalo, por lo que es considerado un \textit{outlier}.\\
				
				Si quisiéramos acceder a la lista de los puntos que son \textit{outliers} bastaría con acceder a la variable a la que hemos igualado la llamada de la función. En este caso habría que acceder a \texttt{anomalias\_temp}.
				
				<<>>=
				anomalias_temp
				@
				
				Y efectivamente tenemos una lista con un 3, el punto que hemos visto que era un \textit{outlier}.\\
					
			\subsection{Segundo ejercicio}
			
				``\textit{El cuarto conjunto de datos, que se empleará para realizar el análisis de detección de datos anómalos utilizando técnicas basadas en la proximidad y en la densidad, estará formado por el número de Mujeres y Hombres inscritos en una serie de cinco seminarios que se han impartido sobre biología. Los datos son: \{Mujeres, Hombres\}: 1. \{9, 9\}; 2. \{9, 7\}; 3. \{11, 11\}; 4. \{2, 1\}; 5. \{11, 9\}.}''
	
\end{document}          
